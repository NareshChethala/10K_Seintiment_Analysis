{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a02ead3-dd98-4079-9873-05805991a63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d1ac39",
   "metadata": {},
   "source": [
    "## Download .idx master files in between required Time Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa62d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2000/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2000/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2000/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2000/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2000/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2000/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2000/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2000/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2001/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2001/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2001/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2001/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2001/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2001/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2001/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2001/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2002/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2002/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2002/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2002/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2002/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2002/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2002/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2002/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2003/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2003/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2003/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2003/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2003/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2003/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2003/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2003/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2004/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2004/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2004/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2004/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2004/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2004/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2004/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2004/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2005/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2005/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2005/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2005/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2005/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2005/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2005/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2005/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2006/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2006/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2006/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2006/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2006/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2006/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2006/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2006/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2007/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2007/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2007/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2007/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2007/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2007/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2007/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2007/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2008/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2008/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2008/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2008/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2008/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2008/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2008/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2008/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2009/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2009/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2009/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2009/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2009/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2009/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2009/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2009/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2010/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2010/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2010/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2010/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2010/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2010/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2010/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2010/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2011/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2011/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2011/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2011/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2011/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2011/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2011/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2011/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2012/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2012/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2012/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2012/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2012/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2012/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2012/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2012/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2013/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2013/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2013/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2013/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2013/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2013/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2013/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2013/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2014/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2014/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2014/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2014/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2014/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2014/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2014/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2014/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2015/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2015/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2015/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2015/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2015/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2015/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2015/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2015/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2016/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2016/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2016/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2016/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2016/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2016/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2016/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2016/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2017/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2017/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2017/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2017/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2017/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2017/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2017/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2017/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2018/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2018/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2018/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2018/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2018/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2018/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2018/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2018/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2019/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2019/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2019/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2019/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2019/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2019/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2019/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2019/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2020/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2020/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2020/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2020/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2020/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2020/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2020/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2020/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2021/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2021/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2021/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2021/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2021/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2021/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2021/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2021/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2022/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2022/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2022/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2022/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2022/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2022/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2022/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2022/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2023/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2023/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2023/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2023/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2023/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2023/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2023/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2023/QTR4/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2024/QTR1/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2024/QTR1/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2024/QTR2/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2024/QTR2/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2024/QTR3/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2024/QTR3/company.idx\n",
      "Attempting to download https://www.sec.gov/Archives/edgar/full-index/2024/QTR4/company.idx...\n",
      "Successfully downloaded https://www.sec.gov/Archives/edgar/full-index/2024/QTR4/company.idx\n",
      "All requested files have been attempted to download.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Base URL for the SEC EDGAR full index\n",
    "base_url = 'https://www.sec.gov/Archives/edgar/full-index/'\n",
    "\n",
    "# Function to download the file, now includes headers parameter\n",
    "def download_file(url, path, headers):\n",
    "    with requests.get(url, headers=headers, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(path, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "# Prompt for start and end year\n",
    "start_year = int(input(\"Enter the start year (YYYY): \"))\n",
    "end_year = int(input(\"Enter the end year (YYYY): \"))\n",
    "save_dir = input('Please Input Path to Your Directory to Download Files:')\n",
    "\n",
    "# Add your user-agent string here\n",
    "headers = {'User-Agent': 'useremail@email.com'}\n",
    "\n",
    "# Iterate over each year and quarter within the specified range\n",
    "for year in range(start_year, end_year + 1):\n",
    "    for quarter in ['QTR1', 'QTR2', 'QTR3', 'QTR4']:\n",
    "        file_url = f\"{base_url}{year}/{quarter}/company.idx\"\n",
    "        save_path = os.path.join(save_dir, f\"{year}_{quarter}_company.idx\")\n",
    "\n",
    "        print(f\"Attempting to download {file_url}...\")\n",
    "\n",
    "        # Make the download attempt\n",
    "        try:\n",
    "            download_file(file_url, save_path, headers)\n",
    "            print(f\"Successfully downloaded {file_url}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download {file_url}. Error: {e}\")\n",
    "\n",
    "        # Respect the SEC's rate limiting\n",
    "        time.sleep(1)  # Sleep for 1 second to avoid hitting rate limit\n",
    "\n",
    "print(\"All requested files have been attempted to download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a448d39e",
   "metadata": {},
   "source": [
    "## Combine all the .idx files into a single dataframe/.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae21b83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to /Users/nareshchethala/Desktop/University/Spring_25/BAIM_660/Project/combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Adjusting pandas display options for more optimized data viewing\n",
    "pd.set_option('display.max_rows', None)  # Display all rows\n",
    "pd.set_option('display.max_columns', None)  # Display all columns\n",
    "pd.set_option('display.width', None)  # Automatically adjust display width to terminal size\n",
    "pd.set_option('display.max_colwidth', None)  # Display full content of each cell\n",
    "\n",
    "#Load data from all EDGAR index files in the specified director\n",
    "def load_data_from_directory(source_dir):\n",
    "    colspecs = [(0, 62), (62, 74), (74, 86), (86, 98), (98, None)]\n",
    "    column_names = ['Company Name', 'Form Type', 'CIK', 'Date Filed', 'Filename']\n",
    "    dataframe_collection = []\n",
    "\n",
    "    # Iterate over each file in the directory\n",
    "    for file_name in os.listdir(source_dir):\n",
    "        if file_name.endswith('.idx'):  # Check for .idx files\n",
    "            file_path = os.path.join(source_dir, file_name)\n",
    "            try:\n",
    "                # Read fixed-width file with specified columns and skip header rows\n",
    "                temp_df = pd.read_fwf(file_path, colspecs=colspecs, skiprows=9, names=column_names)\n",
    "                dataframe_collection.append(temp_df)\n",
    "            except UnicodeDecodeError as e:\n",
    "                print(f'Error reading {file_name}: {e}')\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f'An unexpected error occurred while reading {file_name}: {e}')\n",
    "                continue\n",
    "\n",
    "    if not dataframe_collection:\n",
    "        print(\"No data was loaded. Please check your file paths and names.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Concatenate all DataFrames into one DataFrame\n",
    "    combined_df = pd.concat(dataframe_collection, ignore_index=True)\n",
    "    combined_df.columns = combined_df.columns.str.strip()  # Strip any leading/trailing whitespace from column names\n",
    "    return combined_df\n",
    "\n",
    "def save_to_csv(df, output_path):\n",
    "    \"\"\"Save DataFrame to a CSV file.\"\"\"\n",
    "    try:\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Data saved successfully to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save the DataFrame: {e}\")\n",
    "\n",
    "# Main execution logic\n",
    "if __name__ == \"__main__\":\n",
    "    source_directory = input('Enter/path/to/data/directory: ')  # Get directory containing the data files from user\n",
    "    csv_name = input('Enter the filename for the CSV (e.g., combined_data.csv): ')\n",
    "    output_path = os.path.join(source_directory, csv_name)  # Construct the full path to save the CSV file\n",
    "\n",
    "    # Load data from the specified directory\n",
    "    all_data_df = load_data_from_directory(source_directory)\n",
    "\n",
    "    # Save the data to a CSV file\n",
    "    if not all_data_df.empty:\n",
    "        save_to_csv(all_data_df, output_path)\n",
    "    else:\n",
    "        print(\"No data to save.\")\n",
    "\n",
    "all_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4362eef5",
   "metadata": {},
   "source": [
    "## Load the combined data csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "807c1c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/vt1xc8rs7w9f0fs5spyxbzcc0000gn/T/ipykernel_94872/3083158619.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_data_df = pd.read_csv(output_path) # If running seperately wihtout the download or comined data then replace output_path with the path to the csv file\n"
     ]
    }
   ],
   "source": [
    "output_path = \"/Users/nareshchethala/Desktop/University/Spring_25/BAIM_660/Project/combined_data.csv\" # No need to run this if you are running the code in one go\n",
    "all_data_df = pd.read_csv(output_path) # If running seperately wihtout the download or comined data then replace output_path with the path to the csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54587e0c",
   "metadata": {},
   "source": [
    "## To extract the html content from the company filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18276943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This one works\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def extract_filing_html_directly(row, user_agent_email):\n",
    "    \"\"\"\n",
    "    Extracts the actual 10-K filing HTML content from a row in .idx using the real HTML URL.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        filename = row['Filename'].strip().replace(\" \", \"\")\n",
    "        path_parts = filename.split(\"/\")\n",
    "\n",
    "        if len(path_parts) < 4:\n",
    "            print(f\"Invalid path in Filename: {filename}\")\n",
    "            return None, None\n",
    "\n",
    "        cik = path_parts[2]\n",
    "        accession_with_dashes = path_parts[3]\n",
    "        accession_nodashes = accession_with_dashes.replace(\"-\", \"\")\n",
    "        index_filename = accession_with_dashes + \"-index.htm\"\n",
    "\n",
    "        index_url = f\"https://www.sec.gov/Archives/edgar/data/{cik}/{accession_nodashes}/{index_filename}\"\n",
    "        headers = {\"User-Agent\": user_agent_email}\n",
    "\n",
    "        response = requests.get(index_url, headers=headers, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to load index page: {index_url}\")\n",
    "            return None, None\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        doc_table = soup.find(\"table\", class_=\"tableFile\")\n",
    "        if doc_table is None:\n",
    "            print(f\"Could not find document table at: {index_url}\")\n",
    "            return None, None\n",
    "\n",
    "        doc_link_tag = doc_table.find(\"a\", href=lambda href: href and href.endswith(\".htm\") and not href.endswith(\"-index.htm\"))\n",
    "        if doc_link_tag is None:\n",
    "            print(f\"No .htm filing document found in index page: {index_url}\")\n",
    "            return None, None\n",
    "\n",
    "        primary_doc = doc_link_tag['href'].lstrip(\"/\")  # remove leading slash\n",
    "        filing_url = f\"https://www.sec.gov/{primary_doc}\"  # FIXED — no double Archives\n",
    "\n",
    "        filing_response = requests.get(filing_url, headers=headers, timeout=15)\n",
    "        if filing_response.status_code == 200:\n",
    "            print(f\"Downloaded: {filing_url}\")\n",
    "            return filing_url, filing_response.text\n",
    "        else:\n",
    "            print(f\"Failed to download filing from: {filing_url}\")\n",
    "            return filing_url, None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b9248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def download_multiple_10k_filings(df, user_agent_email):\n",
    "#     \"\"\"\n",
    "#     Show how many 10-Ks are available, let the user choose how many to download,\n",
    "#     and return a DataFrame with filing metadata and text.\n",
    "#     \"\"\"\n",
    "#     # Step 1: Filter for 10-Ks\n",
    "#     tenk_df = df[df['Form Type'].str.upper() == '10-K'].reset_index(drop=True)\n",
    "#     total = len(tenk_df)\n",
    "\n",
    "#     if total == 0:\n",
    "#         print(\"No 10-K filings found in the dataset.\")\n",
    "#         return pd.DataFrame()\n",
    "\n",
    "#     print(f\"Found {total} 10-K filings in the dataset.\")\n",
    "    \n",
    "#     # Step 2: Ask user for how many to download\n",
    "#     while True:\n",
    "#         try:\n",
    "#             limit = int(input(f\"Enter the number of 10-K filings to download (1 to {total}): \"))\n",
    "#             if 1 <= limit <= total:\n",
    "#                 break\n",
    "#             else:\n",
    "#                 print(f\"Please enter a number between 1 and {total}.\")\n",
    "#         except ValueError:\n",
    "#             print(\"Please enter a valid integer.\")\n",
    "\n",
    "#     # Step 3: Download filings\n",
    "#     results = []\n",
    "#     for idx, row in tenk_df.head(limit).iterrows():\n",
    "#         url, html_text = extract_filing_html_directly(row, user_agent_email)\n",
    "#         if html_text:\n",
    "#             results.append({\n",
    "#                 \"Company Name\": row['Company Name'],\n",
    "#                 \"CIK\": row['CIK'],\n",
    "#                 \"Date Filed\": row['Date Filed'],\n",
    "#                 \"Filing URL\": url,\n",
    "#                 \"Filing Text\": html_text\n",
    "#             })\n",
    "\n",
    "#     return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b15e68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = input(\"Please input the dataframe name if loaded already:\")\n",
    "\n",
    "# # Downloading mulitple 10K filings\n",
    "# filings_df = download_multiple_10k_filings(df, \"nareshchandra.chethala@gmail.com\")\n",
    "\n",
    "# # Preview\n",
    "# print(filings_df[['Company Name', 'Filing URL']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7953e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_row = df[df['Form Type'] == '10-K'].iloc[0]\n",
    "# url, html_text = extract_filing_html_directly(sample_row, \"nareshchandra.chethala@gmail.com\")\n",
    "\n",
    "# if html_text:\n",
    "#     print(\" Filing text preview:\\n\")\n",
    "#     print(html_text[:1000])\n",
    "# else:\n",
    "#     print(\"No filing text returned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cae2c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(html_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "974afb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_filing_html(filing_html):\n",
    "    \"\"\"\n",
    "    Cleans the full HTML of a 10-K filing to extract readable plain text.\n",
    "    Removes scripts, styles, and unnecessary whitespace.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        soup = BeautifulSoup(filing_html, \"html.parser\")\n",
    "\n",
    "        # Remove unwanted tags\n",
    "        for tag in soup([\"script\", \"style\", \"header\", \"footer\", \"nav\", \"noscript\"]):\n",
    "            tag.decompose()\n",
    "\n",
    "        # Extract text from the body if present\n",
    "        body = soup.find(\"body\")\n",
    "        raw_text = body.get_text(separator=\"\\n\") if body else soup.get_text(separator=\"\\n\")\n",
    "\n",
    "        # Normalize whitespace\n",
    "        lines = [line.strip() for line in raw_text.splitlines()]\n",
    "        clean_text = \"\\n\".join(line for line in lines if line)\n",
    "\n",
    "        return clean_text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Error cleaning HTML: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8da765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_text = clean_filing_html(html_text)\n",
    "# print(\" Cleaned text preview:\\n\")\n",
    "# print(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a6847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(clean_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f45e990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_multiple_10k_filings(df, user_agent_email):\n",
    "    \"\"\"\n",
    "    Show how many 10-Ks are available, let the user choose how many to download,\n",
    "    and return a DataFrame with filing metadata and text.\n",
    "    \"\"\"\n",
    "    tenk_df = df[df['Form Type'].str.upper() == '10-K'].reset_index(drop=True)\n",
    "    total = len(tenk_df)\n",
    "\n",
    "    if total == 0:\n",
    "        print(\"No 10-K filings found in the dataset.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f\"🔍 Found {total} 10-K filings in the dataset.\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            limit = int(input(f\"Enter the number of 10-K filings to download (1 to {total}): \"))\n",
    "            if 1 <= limit <= total:\n",
    "                break\n",
    "            else:\n",
    "                print(f\"⚠️ Please enter a number between 1 and {total}.\")\n",
    "        except ValueError:\n",
    "            print(\"⚠️ Please enter a valid integer.\")\n",
    "\n",
    "    results = []\n",
    "    for idx, row in tenk_df.head(limit).iterrows():\n",
    "        url, html_text = extract_filing_html_directly(row, user_agent_email)\n",
    "        if html_text:\n",
    "            cleaned_text = clean_filing_html(html_text)\n",
    "            results.append({\n",
    "                \"Company Name\": row['Company Name'],\n",
    "                \"CIK\": row['CIK'],\n",
    "                \"Date Filed\": row['Date Filed'],\n",
    "                \"Filing URL\": url,\n",
    "                \"Filing Text\": html_text,\n",
    "                \"Cleaned Text\": cleaned_text\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25b13555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/vt1xc8rs7w9f0fs5spyxbzcc0000gn/T/ipykernel_94872/3536074714.py:1: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"/Users/nareshchethala/Desktop/University/Spring_25/BAIM_660/Project/combined_data.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Found 197132 10-K filings in the dataset.\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1084869/000143774920019622/flws20200628b_10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1667615/000107878220000695/f10k053120_10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1753648/000149315220017860/form10-k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1591588/000156459020043316/amrk-10k_20200630.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/1750/000110465920085310/air-20200531x10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1300938/000118518520001098/abcoenergy20191231_10k.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/1138723/000156459020041201/aray-10k_20200630.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/849401/000143774920015110/admt20200331_10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/828530/000155335020000885/adfk_10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/352991/000173112220000902/e2089_10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1040470/000165495420009618/aehr_10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1532390/000106299320003916/form10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/874710/000110465920109282/tm2024734d1_10k.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/1387467/000138746720000047/aosl630202010k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/855787/000143774920020157/aphe20201231_10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/713425/000162828020010300/amswa-20200430x10k.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/945828/000118518520001310/amerityre20200630_10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1015383/000149315220016303/form10-k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/6207/000110465920086542/tm2024144d1_10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1650205/000126246320000368/andes7123119.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/1275187/000127518720000024/ango-20200531.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1570132/000155335020000589/anvi_10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1490054/000144586620001088/vbhi_10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1273636/000119312520249103/d864197d10k.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/109563/000010956320000083/ait-2020630x10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1755101/000144586620001404/alds_10k.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/1487198/000148719820000010/aspu-20200430.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1001907/000156459020042788/astc-10k_20200630.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/826253/000121390020017386/f10k2020_aurasystemsinc.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/8670/000000867020000032/adp-20200630.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/1377789/000137778920000062/avnw-20200703.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/8858/000000885820000025/avt-20200627x10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1724001/000147793220004445/axel_10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1672571/000101738620000200/achison_20200331-10k.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/1468328/000156459020038909/adus-10k_20191231.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/730464/000155837020010728/atge-20200630x10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1755953/000121390020028737/MainDocument.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1584754/000121390020023254/f10k2020_akoustistech.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/745543/000074554320000014/atpt06202018_10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/745543/000074554320000025/atpt06302020_10k.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/1748790/000174879020000025/amcr-20200630.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1707258/000121390020026967/f10k2020_amesiteinc.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1681282/000149315220012502/form10-k.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/1499684/000164033420001697/acez_10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1625285/000162528520000004/reviewedform-10-k-20181031.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1666267/000121390020025697/f10k2019_arrestageintern.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1498148/000116169720000334/form_10-k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1762303/000119312520233145/d80602d10k.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/1299709/000129970920000156/a10-k20200630doc.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/725929/000168316820002821/b2digital_10k-033120.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/842023/000143774920018754/tech20200630_10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/73290/000151316220000185/form10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/875729/000107997320000805/bion_10k-063020.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/715812/000071581220000004/bsyn043020.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1630113/000149315220013313/form10-k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1580149/000152013820000356/bivi-20200630_10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1575345/000116169720000341/form_10-k.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/1073349/000107334920000095/epay-20200630.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/13573/000143774920020178/bwl-a20200630_10k.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/746598/000074659820000097/brc-20200731.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1567771/000149315220018067/form10-k.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/703351/000070335120000059/eat202062410k.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/1383312/000138331220000055/br-20200630.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/15847/000143774920015329/buks20200430_10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1634117/000163411720000041/bned-20200502x10kq420.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1808898/000119312520252381/d899221d10k.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/1786352/000156459020041865/bill-10k_20200630.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1428389/000121390020017462/f10k2020_bloxinc.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1765826/000159991620000080/blubuzzard_10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1416697/000149315220016934/form10-k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1407583/000105291820000235/bunkerhill10ksep17-20final.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1430319/000147793220004833/cct_10k.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/16058/000156459020040205/caci-10k_20200630.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/16160/000001616020000078/calm-20200530.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/16732/000001673220000111/cpb-20200802.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1680132/000168013220000014/csui10k.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/19446/000001944620000073/cmd-20200731.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/721371/000072137120000089/a20q410k063020form10-k.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/17843/000001784320000071/crs630202010k.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/1016178/000101617820000015/carv-20200331.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/749038/000110465920105213/tm2024746-1_10k.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/1609702/000160970220000015/cdk-20200630.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/771856/000162828020010734/csbr10-k4302020.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1015155/000114036120019768/brhc10014670_10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/15357/000110465920108359/tm2024736d1_10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1413263/000121390020017170/f10k2020_chinajojodrug.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1434674/000154972720000038/chndform10kjune302020.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/1262976/000126297620000060/cmpr0630202010-k.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/723254/000072325420000025/ctas-20200531.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/858877/000085887720000010/csco-2020725x10k.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/21076/000002107620000016/clx-20200630.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1522222/000118518520001268/cls20200531_10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1729637/000147793220005246/coco_10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1089143/000149315220016754/form10-k.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/23197/000002319720000127/cmtl-20200731.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/23217/000156459020033366/cag-10k_20200531.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1005101/000143774920020370/cncgd20200630_10k.htm\n",
      "Downloaded: https://www.sec.gov/Archives/edgar/data/1006830/000143774920020029/cbkm20200630_10k.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/900075/000090007520000021/cprt-20200731.htm\n",
      "Downloaded: https://www.sec.gov/ix?doc=/Archives/edgar/data/1024305/000102430520000084/coty-20200630.htm\n",
      "                       Company Name  \\\n",
      "0             1 800 FLOWERS COM INC   \n",
      "1              3AM TECHNOLOGIES INC   \n",
      "2  8i Enterprises Acquisition Corp.   \n",
      "3      A-Mark Precious Metals, Inc.   \n",
      "4                          AAR CORP   \n",
      "\n",
      "                                          Filing URL  \n",
      "0  https://www.sec.gov/Archives/edgar/data/108486...  \n",
      "1  https://www.sec.gov/Archives/edgar/data/166761...  \n",
      "2  https://www.sec.gov/Archives/edgar/data/175364...  \n",
      "3  https://www.sec.gov/Archives/edgar/data/159158...  \n",
      "4  https://www.sec.gov/ix?doc=/Archives/edgar/dat...  \n",
      "\n",
      " Sample Cleaned Filing Text:\n",
      "\n",
      "Table of Contents\n",
      "UNITED STATES SECURITIES AND EXCHANGE COMMISSION\n",
      "WASHINGTON, D.C. 20549\n",
      "FORM 10-K\n",
      "☒     ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "For the fiscal year ended\n",
      "June 28, 2020\n",
      "or\n",
      "☐     TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "Commission File No.\n",
      "0-26841\n",
      "1-800-FLOWERS.COM, Inc.\n",
      "(Exact name of registrant as specified in its charter)\n",
      "DELAWARE\n",
      "(State or other jurisdiction of incorporation or organization)\n",
      "11-3117311\n",
      "(I.R.S. Employer Identification No.)\n",
      "One Old Country Road, Carle Place, New York, 11514\n",
      "(Address of principal executive offices) (Zip code)\n",
      "(516) 237-6000\n",
      "(Registrant’s telephone number, including area code)\n",
      "Securities registered pursuant to Section 12(b) of the Act:\n",
      "Title of each class\n",
      "Trading symbol(s)\n",
      "Name of each exchange on which registered\n",
      "Class A common stock\n",
      "FLWS\n",
      "The Nasdaq Stock Market\n",
      "Securities registered pursuant to Section 12(g) of the Act: None\n",
      "Indicate by check mark if the registrant is a well-known seasoned issuer, as defined in Rule 405 of the Securities Act. Yes ☐ No ☒\n",
      "Indicate by check mark if the registrant is not required to file reports pursuant to Section 13 or Section 15 (d) of the Act. Yes ☐ No ☒\n",
      "Indicate by check mark whether the registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities Exchange Act of 1934 during the preceding 12 months (or for such shorter period that the registrant was required to file such reports), and (2) has been subject to such filing requirements for the past 90 days. Yes ☒ No ☐\n",
      "Indicate by check mark whether the registrant has submitted electronically every Interactive Data File required to be submitted pursuant to Rule 405 of Regulation S-T (Section 232.405 of this chapter) during the preceding 12 months (or for such shorter period that the registrant was required to submit such files). Yes ☒ No ☐\n",
      "Indicate by check mark whether the registrant is a large accelerate\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/nareshchethala/Desktop/University/Spring_25/BAIM_660/Project/combined_data.csv\")\n",
    "\n",
    "# Run the full process\n",
    "filings_df = download_multiple_10k_filings(df, \"nareshchandra.chethala@gmail.com\")\n",
    "\n",
    "# Preview results\n",
    "print(filings_df[[\"Company Name\", \"Filing URL\"]].head())\n",
    "print(\"\\n Sample Cleaned Filing Text:\\n\")\n",
    "print(filings_df[\"Cleaned Text\"][0][:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bc19f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Company Name  100 non-null    object\n",
      " 1   CIK           100 non-null    object\n",
      " 2   Date Filed    100 non-null    object\n",
      " 3   Filing URL    100 non-null    object\n",
      " 4   Filing Text   100 non-null    object\n",
      " 5   Cleaned Text  100 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 4.8+ KB\n"
     ]
    }
   ],
   "source": [
    "filings_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc4e0379",
   "metadata": {},
   "outputs": [],
   "source": [
    "filings_df = filings_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "67a7ec86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Company Name  100 non-null    object\n",
      " 1   CIK           100 non-null    object\n",
      " 2   Date Filed    100 non-null    object\n",
      " 3   Filing URL    100 non-null    object\n",
      " 4   Filing Text   100 non-null    object\n",
      " 5   Cleaned Text  100 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 4.8+ KB\n"
     ]
    }
   ],
   "source": [
    "filings_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "837ecaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table of Contents\n",
      "UNITED STATES SECURITIES AND EXCHANGE COMMISSION\n",
      "WASHINGTON, D.C. 20549\n",
      "FORM 10-K\n",
      "☒     ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "For the fiscal year ended\n",
      "June 28, 2020\n",
      "or\n",
      "☐     TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "Commission File No.\n",
      "0-26841\n",
      "1-800-FLOWERS.COM, Inc.\n",
      "(Exact name of registrant as specified in its charter)\n",
      "DELAWARE\n",
      "(State or other jurisdiction of incorporation or organization)\n",
      "11-3117311\n",
      "(I.R.S. Employer Identification No.)\n",
      "One Old Country Road, Carle Place, New York, 11514\n",
      "(Address of principal executive offices) (Zip code)\n",
      "(516) 237-6000\n",
      "(Registrant’s telephone number, including area code)\n",
      "Securities registered pursuant to Section 12(b) of the Act:\n",
      "Title of each class\n",
      "Trading symbol(s)\n",
      "Name of each exchange on which registered\n",
      "Class A common stock\n",
      "FLWS\n",
      "The Nasdaq Stock Market\n",
      "Securities registered pursuant to Section 12(g) of the Act: None\n",
      "Indicate by check mark if the registrant is a well-known seasoned issuer, as defined in Rule 405 of the Securities Act. Yes ☐ No ☒\n",
      "Indicate by check mark if the registrant is not required to file reports pursuant to Section 13 or Section 15 (d) of the Act. Yes ☐ No ☒\n",
      "Indicate by check mark whether the registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities Exchange Act of 1934 during the preceding 12 months (or for such shorter period that the registrant was required to file such reports), and (2) has been subject to such filing requirements for the past 90 days. Yes ☒ No ☐\n",
      "Indicate by check mark whether the registrant has submitted electronically every Interactive Data File required to be submitted pursuant to Rule 405 of Regulation S-T (Section 232.405 of this chapter) during the preceding 12 months (or for such shorter period that the registrant was required to submit such files). Yes ☒ No ☐\n",
      "Indicate by check mark whether the registrant is a large accelerate\n"
     ]
    }
   ],
   "source": [
    "#filings_df[\"Cleaned Text\"].head(1)\n",
    "print(filings_df[\"Cleaned Text\"][0][:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16aa6703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_10k_sections(text):\n",
    "    \"\"\"\n",
    "    Extracts Item 1, Item 7, and Item 7A sections from the plain 10-K text.\n",
    "    Returns a dictionary with each section's content.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or len(text) < 100:\n",
    "        return {\"Item 1\": \"\", \"Item 7\": \"\", \"Item 7A\": \"\"}\n",
    "    \n",
    "    patterns = {\n",
    "        \"Item 1\": r\"(item\\s*1[\\.: \\-–—]*business)\",\n",
    "        \"Item 7\": r\"(item\\s*7[\\.: \\-–—]*management[’'`s]{0,2} discussion.*?)\",\n",
    "        \"Item 7A\": r\"(item\\s*7a[\\.: \\-–—]*quantitative.*?)\"\n",
    "    }\n",
    "\n",
    "    matches = []\n",
    "    for key, pattern in patterns.items():\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            matches.append((key, match.start()))\n",
    "\n",
    "    matches.sort(key=lambda x: x[1])\n",
    "    \n",
    "    sections = {}\n",
    "    for i in range(len(matches)):\n",
    "        section_name, start = matches[i]\n",
    "        end = matches[i+1][1] if i + 1 < len(matches) else len(text)\n",
    "        sections[section_name] = text[start:end].strip()\n",
    "\n",
    "    return {\n",
    "        \"Item 1\": sections.get(\"Item 1\", \"\"),\n",
    "        \"Item 7\": sections.get(\"Item 7\", \"\"),\n",
    "        \"Item 7A\": sections.get(\"Item 7A\", \"\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1f7419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named df and \"Cleaned Text\" column holds the plain text\n",
    "sections_df = filings_df[\"Cleaned Text\"].apply(extract_10k_sections).apply(pd.Series)\n",
    "\n",
    "# Add the extracted sections as new columns\n",
    "filings_df[\"Item 1 Text\"] = sections_df[\"Item 1\"]\n",
    "filings_df[\"Item 7 Text\"] = sections_df[\"Item 7\"]\n",
    "filings_df[\"Item 7A Text\"] = sections_df[\"Item 7A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05da1fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 1 Text     0\n",
      "Item 7 Text     0\n",
      "Item 7A Text    0\n",
      "dtype: int64\n",
      "Item 1 Text     67\n",
      "Item 7 Text     63\n",
      "Item 7A Text    71\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(filings_df[[\"Item 1 Text\", \"Item 7 Text\", \"Item 7A Text\"]].isnull().sum())\n",
    "print(filings_df[[\"Item 1 Text\", \"Item 7 Text\", \"Item 7A Text\"]].eq(\"\").sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4952d51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Company Name  100 non-null    object\n",
      " 1   CIK           100 non-null    object\n",
      " 2   Date Filed    100 non-null    object\n",
      " 3   Filing URL    100 non-null    object\n",
      " 4   Filing Text   100 non-null    object\n",
      " 5   Cleaned Text  100 non-null    object\n",
      " 6   Item 1 Text   100 non-null    object\n",
      " 7   Item 7 Text   100 non-null    object\n",
      " 8   Item 7A Text  100 non-null    object\n",
      "dtypes: object(9)\n",
      "memory usage: 7.2+ KB\n"
     ]
    }
   ],
   "source": [
    "filings_df.describe()\n",
    "filings_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d397a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin = filings_df[[\"Company Name\", \"CIK\", \"Date Filed\", \"Filing URL\", \"Item 1 Text\", \"Item 7 Text\", \"Item 7A Text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85cf4e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from nltk) (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd4ae123",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_df = pd.read_csv(\"/Users/nareshchethala/Desktop/University/Spring_25/BAIM_660/Project/Loughran-McDonald_MasterDictionary_1993-2024.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6ef0ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only positive and negative words\n",
    "positive_words = set(lm_df[lm_df[\"Positive\"] > 0][\"Word\"].str.lower())\n",
    "negative_words = set(lm_df[lm_df[\"Negative\"] > 0][\"Word\"].str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff126661",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nareshchethala/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nareshchethala/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def compute_lm_sentiment(text):\n",
    "    if not isinstance(text, str) or len(text.strip()) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [w for w in tokens if w.isalpha() and w not in stop_words]\n",
    "\n",
    "    pos = sum(1 for word in tokens if word in positive_words)\n",
    "    neg = sum(1 for word in tokens if word in negative_words)\n",
    "    total = len(tokens)\n",
    "\n",
    "    return (pos - neg) / total if total > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a892f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "filings_df[\"Item1_LM_Sentiment\"] = filings_df[\"Item 1 Text\"].apply(compute_lm_sentiment)\n",
    "filings_df[\"Item7_LM_Sentiment\"] = filings_df[\"Item 7 Text\"].apply(compute_lm_sentiment)\n",
    "filings_df[\"Item7A_LM_Sentiment\"] = filings_df[\"Item 7A Text\"].apply(compute_lm_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dbb9491a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Date Filed</th>\n",
       "      <th>Filing URL</th>\n",
       "      <th>Filing Text</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Item 1 Text</th>\n",
       "      <th>Item 7 Text</th>\n",
       "      <th>Item 7A Text</th>\n",
       "      <th>Item1_LM_Sentiment</th>\n",
       "      <th>Item7_LM_Sentiment</th>\n",
       "      <th>Item7A_LM_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 800 FLOWERS COM INC</td>\n",
       "      <td>1084869</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/108486...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>Table of Contents\\nUNITED STATES SECURITIES AN...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3AM TECHNOLOGIES INC</td>\n",
       "      <td>1667615</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/166761...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>Item 1. Business.\\nGeneral\\nAs used in this An...</td>\n",
       "      <td>Item 7. Management’s Discussion and Analysis o...</td>\n",
       "      <td></td>\n",
       "      <td>-0.005587</td>\n",
       "      <td>-0.013685</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8i Enterprises Acquisition Corp.</td>\n",
       "      <td>1753648</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/175364...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>UNITED\\nSTATES\\nSECURITIES\\nAND EXCHANGE COMMI...</td>\n",
       "      <td>ITEM\\n1. BUSINESS\\nIntroduction\\n8i\\nEnterpris...</td>\n",
       "      <td>ITEM\\n7. MANAGEMENT’S DISCUSSION AND ANALYSIS ...</td>\n",
       "      <td>ITEM\\n7A. QUANTITATIVE AND QUALITATIVE DISCLOS...</td>\n",
       "      <td>-0.003749</td>\n",
       "      <td>-0.006018</td>\n",
       "      <td>-0.010383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-Mark Precious Metals, Inc.</td>\n",
       "      <td>1591588</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/159158...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ITEM 7A. QUANTITATIVE AND QUALITATIVE DISCLOSU...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.009829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>1750</td>\n",
       "      <td>2020-07</td>\n",
       "      <td>https://www.sec.gov/ix?doc=/Archives/edgar/dat...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;!DOCT...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Company Name      CIK Date Filed  \\\n",
       "0             1 800 FLOWERS COM INC  1084869    2020-09   \n",
       "1              3AM TECHNOLOGIES INC  1667615    2020-09   \n",
       "2  8i Enterprises Acquisition Corp.  1753648    2020-09   \n",
       "3      A-Mark Precious Metals, Inc.  1591588    2020-09   \n",
       "4                          AAR CORP     1750    2020-07   \n",
       "\n",
       "                                          Filing URL  \\\n",
       "0  https://www.sec.gov/Archives/edgar/data/108486...   \n",
       "1  https://www.sec.gov/Archives/edgar/data/166761...   \n",
       "2  https://www.sec.gov/Archives/edgar/data/175364...   \n",
       "3  https://www.sec.gov/Archives/edgar/data/159158...   \n",
       "4  https://www.sec.gov/ix?doc=/Archives/edgar/dat...   \n",
       "\n",
       "                                         Filing Text  \\\n",
       "0  <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "1  <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "2  <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "3  <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "4  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<!DOCT...   \n",
       "\n",
       "                                        Cleaned Text  \\\n",
       "0  Table of Contents\\nUNITED STATES SECURITIES AN...   \n",
       "1  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...   \n",
       "2  UNITED\\nSTATES\\nSECURITIES\\nAND EXCHANGE COMMI...   \n",
       "3  UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...   \n",
       "4                                                      \n",
       "\n",
       "                                         Item 1 Text  \\\n",
       "0                                                      \n",
       "1  Item 1. Business.\\nGeneral\\nAs used in this An...   \n",
       "2  ITEM\\n1. BUSINESS\\nIntroduction\\n8i\\nEnterpris...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                         Item 7 Text  \\\n",
       "0                                                      \n",
       "1  Item 7. Management’s Discussion and Analysis o...   \n",
       "2  ITEM\\n7. MANAGEMENT’S DISCUSSION AND ANALYSIS ...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                        Item 7A Text  Item1_LM_Sentiment  \\\n",
       "0                                                               0.000000   \n",
       "1                                                              -0.005587   \n",
       "2  ITEM\\n7A. QUANTITATIVE AND QUALITATIVE DISCLOS...           -0.003749   \n",
       "3  ITEM 7A. QUANTITATIVE AND QUALITATIVE DISCLOSU...            0.000000   \n",
       "4                                                               0.000000   \n",
       "\n",
       "   Item7_LM_Sentiment  Item7A_LM_Sentiment  \n",
       "0            0.000000             0.000000  \n",
       "1           -0.013685             0.000000  \n",
       "2           -0.006018            -0.010383  \n",
       "3            0.000000            -0.009829  \n",
       "4            0.000000             0.000000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac965d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load FinBERT model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "\n",
    "finbert = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac896ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nareshchethala/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def get_finbert_sentiment(text):\n",
    "    if not isinstance(text, str) or len(text.strip()) < 10:\n",
    "        return 0.0\n",
    "\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = [' '.join(sentences[i:i+5]) for i in range(0, len(sentences), 5)]\n",
    "    sentiments = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            result = finbert(chunk[:512])[0]\n",
    "            score = {\"positive\": 1, \"neutral\": 0, \"negative\": -1}[result['label'].lower()]\n",
    "            sentiments.append(score)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return np.mean(sentiments) if sentiments else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0bcb0eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/vt1xc8rs7w9f0fs5spyxbzcc0000gn/T/ipykernel_94872/2755567337.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_fin[\"Item7_FinBERT_Sentiment\"] = df_fin[\"Item 7 Text\"].apply(get_finbert_sentiment)\n"
     ]
    }
   ],
   "source": [
    "df_fin[\"Item7_FinBERT_Sentiment\"] = df_fin[\"Item 7 Text\"].apply(get_finbert_sentiment)\n",
    "df_fin[\"Item1_FinBERT_Sentiment\"] = df_fin[\"Item 1 Text\"].apply(get_finbert_sentiment)\n",
    "df_fin[\"Item7A_FinBERT_Sentiment\"] = df_fin[\"Item 7A Text\"].apply(get_finbert_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a9d663d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Date Filed</th>\n",
       "      <th>Filing URL</th>\n",
       "      <th>Item 1 Text</th>\n",
       "      <th>Item 7 Text</th>\n",
       "      <th>Item 7A Text</th>\n",
       "      <th>Item7_FinBERT_Sentiment</th>\n",
       "      <th>Item1_FinBERT_Sentiment</th>\n",
       "      <th>Item7A_FinBERT_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 800 FLOWERS COM INC</td>\n",
       "      <td>1084869</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/108486...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3AM TECHNOLOGIES INC</td>\n",
       "      <td>1667615</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/166761...</td>\n",
       "      <td>Item 1. Business.\\nGeneral\\nAs used in this An...</td>\n",
       "      <td>Item 7. Management’s Discussion and Analysis o...</td>\n",
       "      <td></td>\n",
       "      <td>-0.070175</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8i Enterprises Acquisition Corp.</td>\n",
       "      <td>1753648</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/175364...</td>\n",
       "      <td>ITEM\\n1. BUSINESS\\nIntroduction\\n8i\\nEnterpris...</td>\n",
       "      <td>ITEM\\n7. MANAGEMENT’S DISCUSSION AND ANALYSIS ...</td>\n",
       "      <td>ITEM\\n7A. QUANTITATIVE AND QUALITATIVE DISCLOS...</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>-0.027273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-Mark Precious Metals, Inc.</td>\n",
       "      <td>1591588</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/159158...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ITEM 7A. QUANTITATIVE AND QUALITATIVE DISCLOSU...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>1750</td>\n",
       "      <td>2020-07</td>\n",
       "      <td>https://www.sec.gov/ix?doc=/Archives/edgar/dat...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Company Name      CIK Date Filed  \\\n",
       "0             1 800 FLOWERS COM INC  1084869    2020-09   \n",
       "1              3AM TECHNOLOGIES INC  1667615    2020-09   \n",
       "2  8i Enterprises Acquisition Corp.  1753648    2020-09   \n",
       "3      A-Mark Precious Metals, Inc.  1591588    2020-09   \n",
       "4                          AAR CORP     1750    2020-07   \n",
       "\n",
       "                                          Filing URL  \\\n",
       "0  https://www.sec.gov/Archives/edgar/data/108486...   \n",
       "1  https://www.sec.gov/Archives/edgar/data/166761...   \n",
       "2  https://www.sec.gov/Archives/edgar/data/175364...   \n",
       "3  https://www.sec.gov/Archives/edgar/data/159158...   \n",
       "4  https://www.sec.gov/ix?doc=/Archives/edgar/dat...   \n",
       "\n",
       "                                         Item 1 Text  \\\n",
       "0                                                      \n",
       "1  Item 1. Business.\\nGeneral\\nAs used in this An...   \n",
       "2  ITEM\\n1. BUSINESS\\nIntroduction\\n8i\\nEnterpris...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                         Item 7 Text  \\\n",
       "0                                                      \n",
       "1  Item 7. Management’s Discussion and Analysis o...   \n",
       "2  ITEM\\n7. MANAGEMENT’S DISCUSSION AND ANALYSIS ...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                        Item 7A Text  Item7_FinBERT_Sentiment  \\\n",
       "0                                                                    0.000000   \n",
       "1                                                                   -0.070175   \n",
       "2  ITEM\\n7A. QUANTITATIVE AND QUALITATIVE DISCLOS...                -0.083333   \n",
       "3  ITEM 7A. QUANTITATIVE AND QUALITATIVE DISCLOSU...                 0.000000   \n",
       "4                                                                    0.000000   \n",
       "\n",
       "   Item1_FinBERT_Sentiment  Item7A_FinBERT_Sentiment  \n",
       "0                 0.000000                  0.000000  \n",
       "1                 0.083333                  0.000000  \n",
       "2                 0.113636                 -0.027273  \n",
       "3                 0.000000                  0.000000  \n",
       "4                 0.000000                  0.000000  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf195be-3a01-48e7-985c-1026ddae4277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Years: 100%|██████████████████████████████████████| 5/5 [00:42<00:00,  8.43s/it]\n"
     ]
    }
   ],
   "source": [
    "# # Root directory of your data\n",
    "# root_dir = '/Users/nareshchethala/Desktop/University/Spring_25/BAIM_660/Project/Files'\n",
    "\n",
    "# # Store extracted records\n",
    "# records = []\n",
    "\n",
    "# # Traverse all year folders with tqdm\n",
    "# for year in tqdm(os.listdir(root_dir), desc=\"Years\"):\n",
    "#     year_path = os.path.join(root_dir, year)\n",
    "#     if not os.path.isdir(year_path):\n",
    "#         continue\n",
    "\n",
    "#     # Traverse quarter folders\n",
    "#     for quarter in os.listdir(year_path):\n",
    "#         quarter_path = os.path.join(year_path, quarter)\n",
    "#         if not os.path.isdir(quarter_path):\n",
    "#             continue\n",
    "\n",
    "#         # Traverse all files in quarter folder\n",
    "#         for filename in os.listdir(quarter_path):\n",
    "#             # Match only pure 10-K files \n",
    "#             if (\n",
    "#                 '10-K' in filename.upper() and \n",
    "#                 '10-K/A' not in filename.upper() and \n",
    "#                 '10-K-A' not in filename.upper() and \n",
    "#                 filename.lower().endswith('.txt')\n",
    "#             ):\n",
    "#                 try:\n",
    "#                     file_path = os.path.join(quarter_path, filename)\n",
    "\n",
    "#                     # Read file content\n",
    "#                     with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "#                         text = file.read()\n",
    "\n",
    "#                     # Split filename into parts\n",
    "#                     parts = filename.split('_')\n",
    "#                     filing_date = parts[0]\n",
    "#                     filing_type = parts[1]\n",
    "#                     cik = parts[3]\n",
    "#                     accession = parts[4].replace('.txt', '')\n",
    "\n",
    "#                     # Parse date\n",
    "#                     date_obj = datetime.strptime(filing_date, \"%Y%m%d\")\n",
    "#                     year_parsed = date_obj.year\n",
    "#                     month = date_obj.month\n",
    "#                     day = date_obj.day\n",
    "\n",
    "#                     # Append record\n",
    "#                     records.append({\n",
    "#                         'year_folder': year,\n",
    "#                         'quarter_folder': quarter,\n",
    "#                         'filing_date': filing_date,\n",
    "#                         'year': year_parsed,\n",
    "#                         'month': month,\n",
    "#                         'day': day,\n",
    "#                         'filing_type': filing_type,\n",
    "#                         'cik': cik,\n",
    "#                         'accession': accession,\n",
    "#                         'filename': filename,\n",
    "#                         'text': text\n",
    "#                     })\n",
    "\n",
    "#                 except Exception as e:\n",
    "#                     print(f\" Error reading {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816adf61-7a46-42e5-a025-3a55d22f0507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_10k_final = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c76816-bcfb-4e95-938f-dd7a38cb7ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year_folder', 'quarter_folder', 'filing_date', 'year', 'month', 'day',\n",
       "       'filing_type', 'cik', 'accession', 'filename', 'text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_10k_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bb4f9f-8bf7-4d1a-8aaa-342384238de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_folder</th>\n",
       "      <th>quarter_folder</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>filing_type</th>\n",
       "      <th>cik</th>\n",
       "      <th>accession</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220520</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>849399</td>\n",
       "      <td>20220520_10-K_edgar_data_849399_0000849399-22-...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220520_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220613</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>1857910</td>\n",
       "      <td>20220613_10-K_edgar_data_1857910_0001599916-22...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220613_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220414</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>1855751</td>\n",
       "      <td>20220414_10-K_edgar_data_1855751_0001493152-22...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220414_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220404</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>748790</td>\n",
       "      <td>20220404_10-K_edgar_data_748790_0001575872-22-...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220404_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220408</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>1512927</td>\n",
       "      <td>20220408_10-K_edgar_data_1512927_0001410578-22...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220408_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  year_folder quarter_folder filing_date  year  month  day filing_type   cik  \\\n",
       "0        2022           QTR2    20220520  2022      5   20        10-K  data   \n",
       "1        2022           QTR2    20220613  2022      6   13        10-K  data   \n",
       "2        2022           QTR2    20220414  2022      4   14        10-K  data   \n",
       "3        2022           QTR2    20220404  2022      4    4        10-K  data   \n",
       "4        2022           QTR2    20220408  2022      4    8        10-K  data   \n",
       "\n",
       "  accession                                           filename  \\\n",
       "0    849399  20220520_10-K_edgar_data_849399_0000849399-22-...   \n",
       "1   1857910  20220613_10-K_edgar_data_1857910_0001599916-22...   \n",
       "2   1855751  20220414_10-K_edgar_data_1855751_0001493152-22...   \n",
       "3    748790  20220404_10-K_edgar_data_748790_0001575872-22-...   \n",
       "4   1512927  20220408_10-K_edgar_data_1512927_0001410578-22...   \n",
       "\n",
       "                                                text  \n",
       "0  <Header>\\n<FileStats>\\n    <FileName>20220520_...  \n",
       "1  <Header>\\n<FileStats>\\n    <FileName>20220613_...  \n",
       "2  <Header>\\n<FileStats>\\n    <FileName>20220414_...  \n",
       "3  <Header>\\n<FileStats>\\n    <FileName>20220404_...  \n",
       "4  <Header>\\n<FileStats>\\n    <FileName>20220408_...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_10k_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df917370-06fb-4872-8f16-c7c04f1d871c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29302 entries, 0 to 29301\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   year_folder     29302 non-null  object\n",
      " 1   quarter_folder  29302 non-null  object\n",
      " 2   filing_date     29302 non-null  object\n",
      " 3   year            29302 non-null  int64 \n",
      " 4   month           29302 non-null  int64 \n",
      " 5   day             29302 non-null  int64 \n",
      " 6   filing_type     29302 non-null  object\n",
      " 7   cik             29302 non-null  object\n",
      " 8   accession       29302 non-null  object\n",
      " 9   filename        29302 non-null  object\n",
      " 10  text            29302 non-null  object\n",
      "dtypes: int64(3), object(8)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#df_10k_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736b4c25-fcdd-4941-99c5-6dcfe5b2fcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_10k_final.to_csv(\"10K_filings_all_years.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc5483-d3a2-4557-bcf7-37bed6789314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/nareshchethala/Desktop/University/Spring_25/BAIM_660/Project'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d1ee552-3843-4fd8-835f-97890a8af151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_10k_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    # Remove HTML/XML tags (if any)\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)\n",
    "\n",
    "    # Remove SEC header section if present\n",
    "    text = re.sub(r'(?s)<SEC-Header>.*?</SEC-Header>', ' ', text)\n",
    "    text = re.sub(r'(?s)<Header>.*?</Header>', ' ', text)\n",
    "\n",
    "    # Remove file stats or metadata-like sections\n",
    "    text = re.sub(r'(?i)file name.*?\\.txt', ' ', text)\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', ' ', text)\n",
    "\n",
    "    # Remove duplicate underscores, dashes, and asterisks\n",
    "    text = re.sub(r'[_*=-]{2,}', ' ', text)\n",
    "\n",
    "    # Collapse multiple newlines and spaces\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "\n",
    "    # Strip leading/trailing spaces\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a1a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_100=df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f318b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Date Filed</th>\n",
       "      <th>Filing URL</th>\n",
       "      <th>Filing Text</th>\n",
       "      <th>Cleaned Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 800 FLOWERS COM INC</td>\n",
       "      <td>1084869</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/108486...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>Table of Contents\\nUNITED STATES SECURITIES AN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3AM TECHNOLOGIES INC</td>\n",
       "      <td>1667615</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/166761...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8i Enterprises Acquisition Corp.</td>\n",
       "      <td>1753648</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/175364...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>UNITED\\nSTATES\\nSECURITIES\\nAND EXCHANGE COMMI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-Mark Precious Metals, Inc.</td>\n",
       "      <td>1591588</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/159158...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>1750</td>\n",
       "      <td>2020-07</td>\n",
       "      <td>https://www.sec.gov/ix?doc=/Archives/edgar/dat...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;!DOCT...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Company Name      CIK Date Filed  \\\n",
       "0             1 800 FLOWERS COM INC  1084869    2020-09   \n",
       "1              3AM TECHNOLOGIES INC  1667615    2020-09   \n",
       "2  8i Enterprises Acquisition Corp.  1753648    2020-09   \n",
       "3      A-Mark Precious Metals, Inc.  1591588    2020-09   \n",
       "4                          AAR CORP     1750    2020-07   \n",
       "\n",
       "                                          Filing URL  \\\n",
       "0  https://www.sec.gov/Archives/edgar/data/108486...   \n",
       "1  https://www.sec.gov/Archives/edgar/data/166761...   \n",
       "2  https://www.sec.gov/Archives/edgar/data/175364...   \n",
       "3  https://www.sec.gov/Archives/edgar/data/159158...   \n",
       "4  https://www.sec.gov/ix?doc=/Archives/edgar/dat...   \n",
       "\n",
       "                                         Filing Text  \\\n",
       "0  <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "1  <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "2  <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "3  <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "4  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<!DOCT...   \n",
       "\n",
       "                                        Cleaned Text  \n",
       "0  Table of Contents\\nUNITED STATES SECURITIES AN...  \n",
       "1  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...  \n",
       "2  UNITED\\nSTATES\\nSECURITIES\\nAND EXCHANGE COMMI...  \n",
       "3  UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...  \n",
       "4                                                     "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bd5c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_100 = filings_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad5d23e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/vt1xc8rs7w9f0fs5spyxbzcc0000gn/T/ipykernel_91495/4140166921.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_100[\"cleaned_text\"] = df_100[\"Cleaned Text\"].apply(clean_10k_text)  #11mins\n"
     ]
    }
   ],
   "source": [
    "df_100[\"cleaned_text\"] = df_100[\"Cleaned Text\"].apply(clean_10k_text)  #11mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9046bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Date Filed</th>\n",
       "      <th>Filing URL</th>\n",
       "      <th>Filing Text</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 800 FLOWERS COM INC</td>\n",
       "      <td>1084869</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/108486...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>Table of Contents\\nUNITED STATES SECURITIES AN...</td>\n",
       "      <td>Table of Contents\\nUNITED STATES SECURITIES AN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3AM TECHNOLOGIES INC</td>\n",
       "      <td>1667615</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/166761...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8i Enterprises Acquisition Corp.</td>\n",
       "      <td>1753648</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/175364...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>UNITED\\nSTATES\\nSECURITIES\\nAND EXCHANGE COMMI...</td>\n",
       "      <td>UNITED\\nSTATES\\nSECURITIES\\nAND EXCHANGE COMMI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-Mark Precious Metals, Inc.</td>\n",
       "      <td>1591588</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/159158...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...</td>\n",
       "      <td>UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>1750</td>\n",
       "      <td>2020-07</td>\n",
       "      <td>https://www.sec.gov/ix?doc=/Archives/edgar/dat...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;!DOCT...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>CONAGRA BRANDS INC.</td>\n",
       "      <td>23217</td>\n",
       "      <td>2020-07</td>\n",
       "      <td>https://www.sec.gov/ix?doc=/Archives/edgar/dat...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;!DOCT...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>CONCIERGE TECHNOLOGIES INC</td>\n",
       "      <td>1005101</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/100510...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>Table of Contents\\nUNITED STATES\\nSECURITIES A...</td>\n",
       "      <td>Table of Contents\\nUNITED STATES\\nSECURITIES A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>CONSUMERS BANCORP INC /OH/</td>\n",
       "      <td>1006830</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/100683...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...</td>\n",
       "      <td>UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>COPART INC</td>\n",
       "      <td>900075</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/ix?doc=/Archives/edgar/dat...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;!DOCT...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>COTY INC.</td>\n",
       "      <td>1024305</td>\n",
       "      <td>2020-08</td>\n",
       "      <td>https://www.sec.gov/ix?doc=/Archives/edgar/dat...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;!DOCT...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Company Name      CIK Date Filed  \\\n",
       "0              1 800 FLOWERS COM INC  1084869    2020-09   \n",
       "1               3AM TECHNOLOGIES INC  1667615    2020-09   \n",
       "2   8i Enterprises Acquisition Corp.  1753648    2020-09   \n",
       "3       A-Mark Precious Metals, Inc.  1591588    2020-09   \n",
       "4                           AAR CORP     1750    2020-07   \n",
       "..                               ...      ...        ...   \n",
       "95               CONAGRA BRANDS INC.    23217    2020-07   \n",
       "96        CONCIERGE TECHNOLOGIES INC  1005101    2020-09   \n",
       "97        CONSUMERS BANCORP INC /OH/  1006830    2020-09   \n",
       "98                        COPART INC   900075    2020-09   \n",
       "99                         COTY INC.  1024305    2020-08   \n",
       "\n",
       "                                           Filing URL  \\\n",
       "0   https://www.sec.gov/Archives/edgar/data/108486...   \n",
       "1   https://www.sec.gov/Archives/edgar/data/166761...   \n",
       "2   https://www.sec.gov/Archives/edgar/data/175364...   \n",
       "3   https://www.sec.gov/Archives/edgar/data/159158...   \n",
       "4   https://www.sec.gov/ix?doc=/Archives/edgar/dat...   \n",
       "..                                                ...   \n",
       "95  https://www.sec.gov/ix?doc=/Archives/edgar/dat...   \n",
       "96  https://www.sec.gov/Archives/edgar/data/100510...   \n",
       "97  https://www.sec.gov/Archives/edgar/data/100683...   \n",
       "98  https://www.sec.gov/ix?doc=/Archives/edgar/dat...   \n",
       "99  https://www.sec.gov/ix?doc=/Archives/edgar/dat...   \n",
       "\n",
       "                                          Filing Text  \\\n",
       "0   <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "1   <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "2   <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "3   <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "4   <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<!DOCT...   \n",
       "..                                                ...   \n",
       "95  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<!DOCT...   \n",
       "96  <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "97  <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "98  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<!DOCT...   \n",
       "99  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<!DOCT...   \n",
       "\n",
       "                                         Cleaned Text  \\\n",
       "0   Table of Contents\\nUNITED STATES SECURITIES AN...   \n",
       "1   UNITED STATES SECURITIES AND EXCHANGE COMMISSI...   \n",
       "2   UNITED\\nSTATES\\nSECURITIES\\nAND EXCHANGE COMMI...   \n",
       "3   UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...   \n",
       "4                                                       \n",
       "..                                                ...   \n",
       "95                                                      \n",
       "96  Table of Contents\\nUNITED STATES\\nSECURITIES A...   \n",
       "97  UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...   \n",
       "98                                                      \n",
       "99                                                      \n",
       "\n",
       "                                         cleaned_text  \n",
       "0   Table of Contents\\nUNITED STATES SECURITIES AN...  \n",
       "1   UNITED STATES SECURITIES AND EXCHANGE COMMISSI...  \n",
       "2   UNITED\\nSTATES\\nSECURITIES\\nAND EXCHANGE COMMI...  \n",
       "3   UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...  \n",
       "4                                                      \n",
       "..                                                ...  \n",
       "95                                                     \n",
       "96  Table of Contents\\nUNITED STATES\\nSECURITIES A...  \n",
       "97  UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...  \n",
       "98                                                     \n",
       "99                                                     \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfc51bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885b8bdbbf764a0e9f7168b692cbde7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30873, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c926f4dfcf404483b94d77450766ff82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb87c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text_by_tokens(text, tokenizer, max_tokens=512):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    chunks = []\n",
    "\n",
    "    for i in range(0, len(tokens), max_tokens - 50):  # 50 buffer for [CLS], [SEP], etc.\n",
    "        chunk_tokens = tokens[i:i + max_tokens - 50]\n",
    "        chunk = tokenizer.convert_tokens_to_string(chunk_tokens)\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57516a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_scores(chunks):\n",
    "    sentiments = []\n",
    "    for chunk in chunks:\n",
    "        # Tokenize with truncation and ensure it's not oversized\n",
    "        inputs = tokenizer(chunk, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        \n",
    "        # Safety check: discard if too long after tokenization (rare but cautious)\n",
    "        if inputs['input_ids'].shape[1] > 512:\n",
    "            print(\"Skipping oversized chunk\")\n",
    "            continue\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        label = torch.argmax(probs, dim=1).item()\n",
    "        sentiments.append(label)\n",
    "\n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27fcf200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def aggregate_sentiment(sentiments):\n",
    "    if not sentiments:  # catch empty list\n",
    "        return {\"negative\": 0, \"neutral\": 0, \"positive\": 0}\n",
    "\n",
    "    count = Counter(sentiments)\n",
    "    total = len(sentiments)\n",
    "    return {\n",
    "        \"negative\": count[0] / total,\n",
    "        \"neutral\": count[1] / total,\n",
    "        \"positive\": count[2] / total\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "012ab561",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/100: 1 800 FLOWERS COM INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [01:01<1:41:17, 61.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2/100: 3AM TECHNOLOGIES INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [01:11<51:18, 31.41s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3/100: 8i Enterprises Acquisition Corp.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [01:51<57:10, 35.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4/100: A-Mark Precious Metals, Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [03:16<1:27:51, 54.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5/100: AAR CORP\n",
      "Processing 6/100: ABCO Energy, Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [03:47<53:17, 34.01s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 7/100: ACCURAY INC\n",
      "Processing 8/100: ADM TRONICS UNLIMITED, INC.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [04:09<36:52, 24.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 9/100: ADMIRAL FINANCIAL CORP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [04:16<30:19, 19.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10/100: ADVANCED OXYGEN TECHNOLOGIES INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [04:39<31:18, 20.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 11/100: AEHR TEST SYSTEMS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [05:24<40:18, 27.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 12/100: ALKALINE WATER Co INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [06:09<47:02, 32.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 13/100: ALLIED HEALTHCARE PRODUCTS INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [06:37<44:44, 30.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 14/100: ALPHA & OMEGA SEMICONDUCTOR Ltd\n",
      "Processing 15/100: ALPHA ENERGY INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [07:02<32:05, 22.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 16/100: AMERICAN SOFTWARE INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [07:54<41:39, 29.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 17/100: AMERITYRE CORP\n",
      "Processing 18/100: AMMO, INC.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [08:49<39:33, 28.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 19/100: AMREP CORP.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [09:20<39:39, 29.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20/100: ANDES 7 INC.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [09:38<35:16, 26.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 21/100: ANGIODYNAMICS INC\n",
      "Processing 22/100: ANVI GLOBAL HOLDINGS, INC.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [09:52<23:59, 18.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 23/100: APPIPHANY TECHNOLOGIES HOLDINGS CORP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [10:16<25:18, 19.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 24/100: APPLIED GENETIC TECHNOLOGIES CORP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [11:50<48:15, 38.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 25/100: APPLIED INDUSTRIAL TECHNOLOGIES INC\n",
      "Processing 26/100: APPlife Digital Solutions Inc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [12:05<31:18, 25.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 27/100: ASPEN GROUP, INC.\n",
      "Processing 28/100: ASTROTECH Corp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [12:53<29:52, 24.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 29/100: AURA SYSTEMS INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [13:31<32:41, 27.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 30/100: AUTOMATIC DATA PROCESSING INC\n",
      "Processing 31/100: AVIAT NETWORKS, INC.\n",
      "Processing 32/100: AVNET INC\n",
      "Processing 33/100: AXELEREX CORP.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [13:44<16:03, 14.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 34/100: Achison Inc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [13:55<15:10, 13.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 35/100: Addus HomeCare Corp\n",
      "Processing 36/100: Adtalem Global Education Inc.\n",
      "Processing 37/100: Akerna Corp.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [14:39<14:52, 14.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 38/100: Akoustis Technologies, Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [15:21<19:25, 18.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 39/100: All State Properties Holdings, Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [15:32<17:31, 17.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 40/100: All State Properties Holdings, Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [15:43<15:50, 15.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 41/100: Amcor plc\n",
      "Processing 42/100: Amesite Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [16:09<14:21, 14.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 43/100: Anvia Holdings Corp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [16:40<17:17, 18.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 44/100: Ariel Clean Energy, Inc.\n",
      "Processing 45/100: Arma Services Inc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [16:47<11:43, 12.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 46/100: Arrestage International, Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [17:06<12:40, 14.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 47/100: Artificial Intelligence Technology Solutions Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [17:43<17:07, 19.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 48/100: Avita Therapeutics, Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [18:32<23:15, 26.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 49/100: Axos Financial, Inc.\n",
      "Processing 50/100: B2Digital, Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [19:03<18:20, 22.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 51/100: BIO-TECHNE Corp\n",
      "Processing 52/100: BIOMERICA INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [19:36<15:57, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 53/100: BION ENVIRONMENTAL TECHNOLOGIES INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [20:38<22:32, 28.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 54/100: BIOSYNERGY INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [20:57<20:23, 26.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 55/100: BIOTRICITY INC.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [21:38<22:35, 30.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 56/100: BIOVIE INC.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [22:18<24:05, 32.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 57/100: BLACK CACTUS GLOBAL, INC.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [22:38<20:58, 29.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 58/100: BOTTOMLINE TECHNOLOGIES INC /DE/\n",
      "Processing 59/100: BOWL AMERICA INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [22:51<13:09, 19.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 60/100: BRADY CORP\n",
      "Processing 61/100: BRIDGEWAY NATIONAL CORP.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [23:15<10:46, 16.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 62/100: BRINKER INTERNATIONAL, INC\n",
      "Processing 63/100: BROADRIDGE FINANCIAL SOLUTIONS, INC.\n",
      "Processing 64/100: BUTLER NATIONAL CORP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [23:39<07:33, 12.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 65/100: Barnes & Noble Education, Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [24:41<12:29, 21.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 66/100: Benitec Biopharma Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [25:48<17:19, 30.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 67/100: Bill.com Holdings, Inc.\n",
      "Processing 68/100: Blox, Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [26:12<12:41, 23.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 69/100: Blubuzzard, Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [26:26<11:16, 21.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 70/100: Blue Line Protection Group, Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [26:53<11:27, 22.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 71/100: Bunker Hill Mining Corp.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [27:25<12:11, 25.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 72/100: C & C TOURS INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [27:35<09:50, 21.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 73/100: CACI INTERNATIONAL INC /DE/\n",
      "Processing 74/100: CAL-MAINE FOODS INC\n",
      "Processing 75/100: CAMPBELL SOUP CO\n",
      "Processing 76/100: CANNABIS SUISSE CORP.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [27:35<03:24,  8.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 77/100: CANTEL MEDICAL CORP\n",
      "Processing 78/100: CARDINAL HEALTH INC\n",
      "Processing 79/100: CARPENTER TECHNOLOGY CORP\n",
      "Processing 80/100: CARVER BANCORP INC\n",
      "Processing 81/100: CCUR Holdings, Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [28:24<02:55,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 82/100: CDK Global, Inc.\n",
      "Processing 83/100: CHAMPIONS ONCOLOGY, INC.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [29:00<03:10, 11.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 84/100: CHARLES & COLVARD LTD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [30:08<05:05, 19.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 85/100: CHASE GENERAL CORP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [30:27<04:46, 19.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 86/100: CHINA JO-JO DRUGSTORES, INC.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 86/100 [31:37<06:45, 28.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 87/100: CHINA MEDIA INC.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 87/100 [31:53<05:39, 26.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 88/100: CIMPRESS plc\n",
      "Processing 89/100: CINTAS CORP\n",
      "Processing 90/100: CISCO SYSTEMS, INC.\n",
      "Processing 91/100: CLOROX CO /DE/\n",
      "Processing 92/100: CLS Holdings USA, Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [33:08<02:34, 19.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 93/100: COCOLUV INC.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [33:18<02:06, 18.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 94/100: COLLECTORS UNIVERSE INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [34:08<02:20, 23.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 95/100: COMTECH TELECOMMUNICATIONS CORP /DE/\n",
      "Processing 96/100: CONAGRA BRANDS INC.\n",
      "Processing 97/100: CONCIERGE TECHNOLOGIES INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [34:44<00:56, 18.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 98/100: CONSUMERS BANCORP INC /OH/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [35:17<00:00, 21.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 99/100: COPART INC\n",
      "Processing 100/100: COTY INC.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "sentiment_results = []\n",
    "\n",
    "for i, row in tqdm(df_100.iterrows(), total=len(df_100)):\n",
    "    try:\n",
    "        print(f\"Processing {i+1}/{len(df_100)}: {row['Company Name']}\")\n",
    "\n",
    "        # Chunk using token-aware chunking\n",
    "        text_chunks = chunk_text_by_tokens(row['cleaned_text'], tokenizer)\n",
    "\n",
    "        # Get chunk-level sentiments\n",
    "        chunk_sentiments = get_sentiment_scores(text_chunks)\n",
    "\n",
    "        # Aggregate to document-level sentiment\n",
    "        result = aggregate_sentiment(chunk_sentiments)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {i}: {e}\")\n",
    "        result = {\"negative\": None, \"neutral\": None, \"positive\": None}\n",
    "\n",
    "    sentiment_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb73352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "sentiment_df = pd.DataFrame(sentiment_results)\n",
    "\n",
    "# Combine with your original df\n",
    "final_df = pd.concat([df.reset_index(drop=True), sentiment_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43330f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Date Filed</th>\n",
       "      <th>Filing URL</th>\n",
       "      <th>Filing Text</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 800 FLOWERS COM INC</td>\n",
       "      <td>1084869</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/108486...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>Table of Contents\\nUNITED STATES SECURITIES AN...</td>\n",
       "      <td>Table of Contents\\nUNITED STATES SECURITIES AN...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3AM TECHNOLOGIES INC</td>\n",
       "      <td>1667615</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/166761...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8i Enterprises Acquisition Corp.</td>\n",
       "      <td>1753648</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/175364...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>UNITED\\nSTATES\\nSECURITIES\\nAND EXCHANGE COMMI...</td>\n",
       "      <td>UNITED\\nSTATES\\nSECURITIES\\nAND EXCHANGE COMMI...</td>\n",
       "      <td>0.978947</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-Mark Precious Metals, Inc.</td>\n",
       "      <td>1591588</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/159158...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...</td>\n",
       "      <td>UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...</td>\n",
       "      <td>0.877301</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.098160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>1750</td>\n",
       "      <td>2020-07</td>\n",
       "      <td>https://www.sec.gov/ix?doc=/Archives/edgar/dat...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;!DOCT...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Company Name      CIK Date Filed  \\\n",
       "0             1 800 FLOWERS COM INC  1084869    2020-09   \n",
       "1              3AM TECHNOLOGIES INC  1667615    2020-09   \n",
       "2  8i Enterprises Acquisition Corp.  1753648    2020-09   \n",
       "3      A-Mark Precious Metals, Inc.  1591588    2020-09   \n",
       "4                          AAR CORP     1750    2020-07   \n",
       "\n",
       "                                          Filing URL  \\\n",
       "0  https://www.sec.gov/Archives/edgar/data/108486...   \n",
       "1  https://www.sec.gov/Archives/edgar/data/166761...   \n",
       "2  https://www.sec.gov/Archives/edgar/data/175364...   \n",
       "3  https://www.sec.gov/Archives/edgar/data/159158...   \n",
       "4  https://www.sec.gov/ix?doc=/Archives/edgar/dat...   \n",
       "\n",
       "                                         Filing Text  \\\n",
       "0  <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "1  <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "2  <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "3  <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "4  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<!DOCT...   \n",
       "\n",
       "                                        Cleaned Text  \\\n",
       "0  Table of Contents\\nUNITED STATES SECURITIES AN...   \n",
       "1  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...   \n",
       "2  UNITED\\nSTATES\\nSECURITIES\\nAND EXCHANGE COMMI...   \n",
       "3  UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...   \n",
       "4                                                      \n",
       "\n",
       "                                        cleaned_text  negative   neutral  \\\n",
       "0  Table of Contents\\nUNITED STATES SECURITIES AN...  0.666667  0.142857   \n",
       "1  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...  0.928571  0.000000   \n",
       "2  UNITED\\nSTATES\\nSECURITIES\\nAND EXCHANGE COMMI...  0.978947  0.021053   \n",
       "3  UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...  0.877301  0.024540   \n",
       "4                                                     0.000000  0.000000   \n",
       "\n",
       "   positive  \n",
       "0  0.190476  \n",
       "1  0.071429  \n",
       "2  0.000000  \n",
       "3  0.098160  \n",
       "4  0.000000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6281ab6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.063315</td>\n",
       "      <td>0.012926</td>\n",
       "      <td>0.553759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.075750</td>\n",
       "      <td>0.024526</td>\n",
       "      <td>0.432330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.026280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.799866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.126111</td>\n",
       "      <td>0.016841</td>\n",
       "      <td>0.925893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         positive     neutral    negative\n",
       "count  100.000000  100.000000  100.000000\n",
       "mean     0.063315    0.012926    0.553759\n",
       "std      0.075750    0.024526    0.432330\n",
       "min      0.000000    0.000000    0.000000\n",
       "25%      0.000000    0.000000    0.000000\n",
       "50%      0.026280    0.000000    0.799866\n",
       "75%      0.126111    0.016841    0.925893\n",
       "max      0.245902    0.142857    1.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[['positive', 'neutral', 'negative']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16b3b24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Sentiment Scores:\n",
      " positive    0.063315\n",
      "neutral     0.012926\n",
      "negative    0.553759\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "avg_sentiment = final_df[['positive', 'neutral', 'negative']].mean()\n",
    "print(\"Average Sentiment Scores:\\n\", avg_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "042989e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdominant_sentiment\u001b[39m(row):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(row, key=row.get)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m final_df[\u001b[33m'\u001b[39m\u001b[33mdominant_sentiment\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mfinal_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpositive\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mneutral\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnegative\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdominant_sentiment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Count occurrences\u001b[39;00m\n\u001b[32m      7\u001b[39m final_df[\u001b[33m'\u001b[39m\u001b[33mdominant_sentiment\u001b[39m\u001b[33m'\u001b[39m].value_counts()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenv/project10k/lib/python3.13/site-packages/pandas/core/frame.py:10374\u001b[39m, in \u001b[36mDataFrame.apply\u001b[39m\u001b[34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m  10360\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[32m  10362\u001b[39m op = frame_apply(\n\u001b[32m  10363\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  10364\u001b[39m     func=func,\n\u001b[32m   (...)\u001b[39m\u001b[32m  10372\u001b[39m     kwargs=kwargs,\n\u001b[32m  10373\u001b[39m )\n\u001b[32m> \u001b[39m\u001b[32m10374\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mapply\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenv/project10k/lib/python3.13/site-packages/pandas/core/apply.py:916\u001b[39m, in \u001b[36mFrameApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_raw(engine=\u001b[38;5;28mself\u001b[39m.engine, engine_kwargs=\u001b[38;5;28mself\u001b[39m.engine_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenv/project10k/lib/python3.13/site-packages/pandas/core/apply.py:1063\u001b[39m, in \u001b[36mFrameApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m         results, res_index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m         results, res_index = \u001b[38;5;28mself\u001b[39m.apply_series_numba()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenv/project10k/lib/python3.13/site-packages/pandas/core/apply.py:1081\u001b[39m, in \u001b[36mFrameApply.apply_series_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1078\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mmode.chained_assignment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1079\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[32m   1080\u001b[39m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m         results[i] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[32m   1083\u001b[39m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[32m   1084\u001b[39m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[32m   1085\u001b[39m             results[i] = results[i].copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mdominant_sentiment\u001b[39m\u001b[34m(row)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdominant_sentiment\u001b[39m(row):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: '>' not supported between instances of 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "def dominant_sentiment(row):\n",
    "    return max(row, key=row.get)\n",
    "\n",
    "final_df['dominant_sentiment'] = final_df[['positive', 'neutral', 'negative']].apply(dominant_sentiment, axis=1)\n",
    "\n",
    "# Count occurrences\n",
    "final_df['dominant_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cda3e579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# def extract_section(text, item_title):\n",
    "#     \"\"\"\n",
    "#     Extracts the section of a 10-K filing based on the provided item title.\n",
    "#     \"\"\"\n",
    "#     text = text.upper()\n",
    "#     item_title = item_title.upper().strip()\n",
    "\n",
    "#     # Handle different spacing and numbering formats (e.g., ITEM 1A, ITEM1A.)\n",
    "#     pattern = rf\"{item_title}.*?(?=ITEM\\s+\\d+[A-Z]?[.\\s])\"\n",
    "#     match = re.search(pattern, text, re.DOTALL)\n",
    "#     if match:\n",
    "#         return match.group().strip()\n",
    "#     return \"\"\n",
    "\n",
    "def extract_section(text, item_title):\n",
    "    text = text.upper()\n",
    "    item_title = item_title.upper().strip()\n",
    "    pattern = rf\"{item_title}.*?(?=ITEM\\s+\\d+[A-Z]?[.\\s])\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group().strip()\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "721e9842",
   "metadata": {},
   "outputs": [],
   "source": [
    "SECTION_MAP = {\n",
    "    \"risk\": \"ITEM 1A. RISK FACTORS\",\n",
    "    \"mdna\": \"ITEM 7. MANAGEMENT’S DISCUSSION AND ANALYSIS\",\n",
    "    \"business\": \"ITEM 1. BUSINESS\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "916c5af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:43<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "all_section_sentiments = []\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    row_result = {}\n",
    "\n",
    "    for section_key, section_title in SECTION_MAP.items():\n",
    "        try:\n",
    "            section_text = extract_section(row['cleaned_text'], section_title)\n",
    "            if not section_text or len(section_text.split()) < 20:\n",
    "                row_result[f\"{section_key}_sentiment_positive\"] = 0\n",
    "                row_result[f\"{section_key}_sentiment_neutral\"] = 0\n",
    "                row_result[f\"{section_key}_sentiment_negative\"] = 0\n",
    "                continue\n",
    "\n",
    "            # Chunk, Analyze, Aggregate\n",
    "            chunks = chunk_text_by_tokens(section_text, tokenizer)\n",
    "            sentiments = get_sentiment_scores(chunks)\n",
    "            aggregated = aggregate_sentiment(sentiments)\n",
    "\n",
    "            # Store results\n",
    "            for sentiment_type in ['positive', 'neutral', 'negative']:\n",
    "                row_result[f\"{section_key}_sentiment_{sentiment_type}\"] = aggregated[sentiment_type]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in row {i}, section {section_key}: {e}\")\n",
    "            for sentiment_type in ['positive', 'neutral', 'negative']:\n",
    "                row_result[f\"{section_key}_sentiment_{sentiment_type}\"] = None\n",
    "\n",
    "    all_section_sentiments.append(row_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ea5b996",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_df = pd.DataFrame(all_section_sentiments)\n",
    "final_df = pd.concat([df.reset_index(drop=True), section_df], axis=1)\n",
    "final_df.to_csv(\"section_wise_10k_sentiment.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b053337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Date Filed</th>\n",
       "      <th>Filing URL</th>\n",
       "      <th>Filing Text</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>risk_sentiment_positive</th>\n",
       "      <th>risk_sentiment_neutral</th>\n",
       "      <th>risk_sentiment_negative</th>\n",
       "      <th>mdna_sentiment_positive</th>\n",
       "      <th>mdna_sentiment_neutral</th>\n",
       "      <th>mdna_sentiment_negative</th>\n",
       "      <th>business_sentiment_positive</th>\n",
       "      <th>business_sentiment_neutral</th>\n",
       "      <th>business_sentiment_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 800 FLOWERS COM INC</td>\n",
       "      <td>1084869</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/108486...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>Table of Contents\\nUNITED STATES SECURITIES AN...</td>\n",
       "      <td>Table of Contents\\nUNITED STATES SECURITIES AN...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3AM TECHNOLOGIES INC</td>\n",
       "      <td>1667615</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/166761...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8i Enterprises Acquisition Corp.</td>\n",
       "      <td>1753648</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/175364...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>UNITED\\nSTATES\\nSECURITIES\\nAND EXCHANGE COMMI...</td>\n",
       "      <td>UNITED\\nSTATES\\nSECURITIES\\nAND EXCHANGE COMMI...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-Mark Precious Metals, Inc.</td>\n",
       "      <td>1591588</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/159158...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...</td>\n",
       "      <td>UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>1750</td>\n",
       "      <td>2020-07</td>\n",
       "      <td>https://www.sec.gov/ix?doc=/Archives/edgar/dat...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;!DOCT...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Company Name      CIK Date Filed  \\\n",
       "0             1 800 FLOWERS COM INC  1084869    2020-09   \n",
       "1              3AM TECHNOLOGIES INC  1667615    2020-09   \n",
       "2  8i Enterprises Acquisition Corp.  1753648    2020-09   \n",
       "3      A-Mark Precious Metals, Inc.  1591588    2020-09   \n",
       "4                          AAR CORP     1750    2020-07   \n",
       "\n",
       "                                          Filing URL  \\\n",
       "0  https://www.sec.gov/Archives/edgar/data/108486...   \n",
       "1  https://www.sec.gov/Archives/edgar/data/166761...   \n",
       "2  https://www.sec.gov/Archives/edgar/data/175364...   \n",
       "3  https://www.sec.gov/Archives/edgar/data/159158...   \n",
       "4  https://www.sec.gov/ix?doc=/Archives/edgar/dat...   \n",
       "\n",
       "                                         Filing Text  \\\n",
       "0  <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "1  <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "2  <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "3  <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "4  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<!DOCT...   \n",
       "\n",
       "                                        Cleaned Text  \\\n",
       "0  Table of Contents\\nUNITED STATES SECURITIES AN...   \n",
       "1  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...   \n",
       "2  UNITED\\nSTATES\\nSECURITIES\\nAND EXCHANGE COMMI...   \n",
       "3  UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...   \n",
       "4                                                      \n",
       "\n",
       "                                        cleaned_text  risk_sentiment_positive  \\\n",
       "0  Table of Contents\\nUNITED STATES SECURITIES AN...                      0.0   \n",
       "1  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...                      0.0   \n",
       "2  UNITED\\nSTATES\\nSECURITIES\\nAND EXCHANGE COMMI...                      0.0   \n",
       "3  UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...                      0.0   \n",
       "4                                                                         0.0   \n",
       "\n",
       "   risk_sentiment_neutral  risk_sentiment_negative  mdna_sentiment_positive  \\\n",
       "0                     0.0                      0.0                 0.000000   \n",
       "1                     0.0                      0.0                 0.166667   \n",
       "2                     0.0                      0.0                 0.000000   \n",
       "3                     0.0                      0.0                 0.000000   \n",
       "4                     0.0                      0.0                 0.000000   \n",
       "\n",
       "   mdna_sentiment_neutral  mdna_sentiment_negative  \\\n",
       "0                     0.0                 0.000000   \n",
       "1                     0.0                 0.833333   \n",
       "2                     0.0                 0.000000   \n",
       "3                     0.0                 0.000000   \n",
       "4                     0.0                 0.000000   \n",
       "\n",
       "   business_sentiment_positive  business_sentiment_neutral  \\\n",
       "0                          0.0                         0.0   \n",
       "1                          0.0                         0.0   \n",
       "2                          0.0                         0.0   \n",
       "3                          0.0                         0.0   \n",
       "4                          0.0                         0.0   \n",
       "\n",
       "   business_sentiment_negative  \n",
       "0                          0.0  \n",
       "1                          1.0  \n",
       "2                          0.0  \n",
       "3                          0.0  \n",
       "4                          0.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c42140ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_scores(chunks):\n",
    "    sentiments = []\n",
    "    for chunk in chunks:\n",
    "        inputs = tokenizer(chunk, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        \n",
    "        if inputs['input_ids'].shape[1] > 512:\n",
    "            print(\"Skipping oversized chunk\")\n",
    "            continue\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        label = torch.argmax(probs, dim=1).item()\n",
    "        sentiments.append(label)\n",
    "\n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "226ba902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def extract_relevant_sections(full_text):\n",
    "    \"\"\"\n",
    "    Extracts important 10-K sections for sentiment analysis.\n",
    "    \"\"\"\n",
    "    sections = [\n",
    "        \"ITEM 1A. RISK FACTORS\",\n",
    "        \"ITEM 7. MANAGEMENT’S DISCUSSION AND ANALYSIS\",\n",
    "        \"ITEM 1. BUSINESS\"\n",
    "    ]\n",
    "    extracted = \"\"\n",
    "    for section in sections:\n",
    "        extracted += \"\\n\" + extract_section(full_text, section)\n",
    "    return extracted.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cdada258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/100: 1 800 FLOWERS COM INC\n",
      "Processing 2/100: 3AM TECHNOLOGIES INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:03<02:48,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3/100: 8i Enterprises Acquisition Corp.\n",
      "Processing 4/100: A-Mark Precious Metals, Inc.\n",
      "Processing 5/100: AAR CORP\n",
      "Processing 6/100: ABCO Energy, Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:07<01:50,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 7/100: ACCURAY INC\n",
      "Processing 8/100: ADM TRONICS UNLIMITED, INC.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:11<02:20,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 9/100: ADMIRAL FINANCIAL CORP\n",
      "Processing 10/100: ADVANCED OXYGEN TECHNOLOGIES INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:13<01:50,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 11/100: AEHR TEST SYSTEMS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:13<01:32,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 12/100: ALKALINE WATER Co INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:24<04:47,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 13/100: ALLIED HEALTHCARE PRODUCTS INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:27<04:24,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 14/100: ALPHA & OMEGA SEMICONDUCTOR Ltd\n",
      "Processing 15/100: ALPHA ENERGY INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:35<05:01,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 16/100: AMERICAN SOFTWARE INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:36<03:59,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 17/100: AMERITYRE CORP\n",
      "Processing 18/100: AMMO, INC.\n",
      "Processing 19/100: AMREP CORP.\n",
      "Processing 20/100: ANDES 7 INC.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [00:38<02:11,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 21/100: ANGIODYNAMICS INC\n",
      "Processing 22/100: ANVI GLOBAL HOLDINGS, INC.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [00:40<01:55,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 23/100: APPIPHANY TECHNOLOGIES HOLDINGS CORP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [00:41<00:58,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 24/100: APPLIED GENETIC TECHNOLOGIES CORP\n",
      "Processing 25/100: APPLIED INDUSTRIAL TECHNOLOGIES INC\n",
      "Processing 26/100: APPlife Digital Solutions Inc\n",
      "Processing 27/100: ASPEN GROUP, INC.\n",
      "Processing 28/100: ASTROTECH Corp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [00:59<03:42,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 29/100: AURA SYSTEMS INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [01:01<03:28,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 30/100: AUTOMATIC DATA PROCESSING INC\n",
      "Processing 31/100: AVIAT NETWORKS, INC.\n",
      "Processing 32/100: AVNET INC\n",
      "Processing 33/100: AXELEREX CORP.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [01:02<01:47,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 34/100: Achison Inc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [01:03<01:36,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 35/100: Addus HomeCare Corp\n",
      "Processing 36/100: Adtalem Global Education Inc.\n",
      "Processing 37/100: Akerna Corp.\n",
      "Processing 38/100: Akoustis Technologies, Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [01:06<01:14,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 39/100: All State Properties Holdings, Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [01:08<01:21,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 40/100: All State Properties Holdings, Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [01:10<01:27,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 41/100: Amcor plc\n",
      "Processing 42/100: Amesite Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [01:16<01:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 43/100: Anvia Holdings Corp\n",
      "Processing 44/100: Ariel Clean Energy, Inc.\n",
      "Processing 45/100: Arma Services Inc\n",
      "Processing 46/100: Arrestage International, Inc.\n",
      "Processing 47/100: Artificial Intelligence Technology Solutions Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [01:24<01:43,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 48/100: Avita Therapeutics, Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [01:26<01:40,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 49/100: Axos Financial, Inc.\n",
      "Processing 50/100: B2Digital, Inc.\n",
      "Processing 51/100: BIO-TECHNE Corp\n",
      "Processing 52/100: BIOMERICA INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [01:39<02:01,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 53/100: BION ENVIRONMENTAL TECHNOLOGIES INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [02:02<03:00,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 54/100: BIOSYNERGY INC\n",
      "Processing 55/100: BIOTRICITY INC.\n",
      "Processing 56/100: BIOVIE INC.\n",
      "Processing 57/100: BLACK CACTUS GLOBAL, INC.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [02:06<02:23,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 58/100: BOTTOMLINE TECHNOLOGIES INC /DE/\n",
      "Processing 59/100: BOWL AMERICA INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [02:07<01:40,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 60/100: BRADY CORP\n",
      "Processing 61/100: BRIDGEWAY NATIONAL CORP.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [02:07<00:39,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 62/100: BRINKER INTERNATIONAL, INC\n",
      "Processing 63/100: BROADRIDGE FINANCIAL SOLUTIONS, INC.\n",
      "Processing 64/100: BUTLER NATIONAL CORP\n",
      "Processing 65/100: Barnes & Noble Education, Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [02:08<00:31,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 66/100: Benitec Biopharma Inc.\n",
      "Processing 67/100: Bill.com Holdings, Inc.\n",
      "Processing 68/100: Blox, Inc.\n",
      "Processing 69/100: Blubuzzard, Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [02:10<00:25,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 70/100: Blue Line Protection Group, Inc.\n",
      "Processing 71/100: Bunker Hill Mining Corp.\n",
      "Processing 72/100: C & C TOURS INC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [02:12<00:21,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 73/100: CACI INTERNATIONAL INC /DE/\n",
      "Processing 74/100: CAL-MAINE FOODS INC\n",
      "Processing 75/100: CAMPBELL SOUP CO\n",
      "Processing 76/100: CANNABIS SUISSE CORP.\n",
      "Processing 77/100: CANTEL MEDICAL CORP\n",
      "Processing 78/100: CARDINAL HEALTH INC\n",
      "Processing 79/100: CARPENTER TECHNOLOGY CORP\n",
      "Processing 80/100: CARVER BANCORP INC\n",
      "Processing 81/100: CCUR Holdings, Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [02:15<00:10,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 82/100: CDK Global, Inc.\n",
      "Processing 83/100: CHAMPIONS ONCOLOGY, INC.\n",
      "Processing 84/100: CHARLES & COLVARD LTD\n",
      "Processing 85/100: CHASE GENERAL CORP\n",
      "Processing 86/100: CHINA JO-JO DRUGSTORES, INC.\n",
      "Processing 87/100: CHINA MEDIA INC.\n",
      "Processing 88/100: CIMPRESS plc\n",
      "Processing 89/100: CINTAS CORP\n",
      "Processing 90/100: CISCO SYSTEMS, INC.\n",
      "Processing 91/100: CLOROX CO /DE/\n",
      "Processing 92/100: CLS Holdings USA, Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:44<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 93/100: COCOLUV INC.\n",
      "Processing 94/100: COLLECTORS UNIVERSE INC\n",
      "Processing 95/100: COMTECH TELECOMMUNICATIONS CORP /DE/\n",
      "Processing 96/100: CONAGRA BRANDS INC.\n",
      "Processing 97/100: CONCIERGE TECHNOLOGIES INC\n",
      "Processing 98/100: CONSUMERS BANCORP INC /OH/\n",
      "Processing 99/100: COPART INC\n",
      "Processing 100/100: COTY INC.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_results = []\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    try:\n",
    "        print(f\"Processing {i+1}/{len(df)}: {row['Company Name']}\")\n",
    "\n",
    "        # Step 1: Extract key sections\n",
    "        focus_text = extract_relevant_sections(row['cleaned_text'])\n",
    "\n",
    "        # Step 2: Chunk by tokens\n",
    "        text_chunks = chunk_text_by_tokens(focus_text, tokenizer)\n",
    "\n",
    "        # Step 3: Get chunk-level sentiments\n",
    "        chunk_sentiments = get_sentiment_scores(text_chunks)\n",
    "\n",
    "        # Step 4: Aggregate to document-level\n",
    "        result = aggregate_sentiment(chunk_sentiments)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on row {i}: {e}\")\n",
    "        result = {\"negative\": None, \"neutral\": None, \"positive\": None}\n",
    "\n",
    "    sentiment_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5baefed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join results and export\n",
    "sentiment_df = pd.DataFrame(sentiment_results)\n",
    "final_df = pd.concat([df.reset_index(drop=True), sentiment_df], axis=1)\n",
    "final_df.to_csv(\"10k_sentiment_focused_sections.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef46cad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Date Filed</th>\n",
       "      <th>Filing URL</th>\n",
       "      <th>Filing Text</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 800 FLOWERS COM INC</td>\n",
       "      <td>1084869</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/108486...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>Table of Contents\\nUNITED STATES SECURITIES AN...</td>\n",
       "      <td>Table of Contents\\nUNITED STATES SECURITIES AN...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3AM TECHNOLOGIES INC</td>\n",
       "      <td>1667615</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/166761...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8i Enterprises Acquisition Corp.</td>\n",
       "      <td>1753648</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/175364...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>UNITED\\nSTATES\\nSECURITIES\\nAND EXCHANGE COMMI...</td>\n",
       "      <td>UNITED\\nSTATES\\nSECURITIES\\nAND EXCHANGE COMMI...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-Mark Precious Metals, Inc.</td>\n",
       "      <td>1591588</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/159158...</td>\n",
       "      <td>&lt;DOCUMENT&gt;\\n&lt;TYPE&gt;10-K\\n&lt;SEQUENCE&gt;1\\n&lt;FILENAME...</td>\n",
       "      <td>UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...</td>\n",
       "      <td>UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>1750</td>\n",
       "      <td>2020-07</td>\n",
       "      <td>https://www.sec.gov/ix?doc=/Archives/edgar/dat...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;!DOCT...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Company Name      CIK Date Filed  \\\n",
       "0             1 800 FLOWERS COM INC  1084869    2020-09   \n",
       "1              3AM TECHNOLOGIES INC  1667615    2020-09   \n",
       "2  8i Enterprises Acquisition Corp.  1753648    2020-09   \n",
       "3      A-Mark Precious Metals, Inc.  1591588    2020-09   \n",
       "4                          AAR CORP     1750    2020-07   \n",
       "\n",
       "                                          Filing URL  \\\n",
       "0  https://www.sec.gov/Archives/edgar/data/108486...   \n",
       "1  https://www.sec.gov/Archives/edgar/data/166761...   \n",
       "2  https://www.sec.gov/Archives/edgar/data/175364...   \n",
       "3  https://www.sec.gov/Archives/edgar/data/159158...   \n",
       "4  https://www.sec.gov/ix?doc=/Archives/edgar/dat...   \n",
       "\n",
       "                                         Filing Text  \\\n",
       "0  <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "1  <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "2  <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "3  <DOCUMENT>\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME...   \n",
       "4  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<!DOCT...   \n",
       "\n",
       "                                        Cleaned Text  \\\n",
       "0  Table of Contents\\nUNITED STATES SECURITIES AN...   \n",
       "1  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...   \n",
       "2  UNITED\\nSTATES\\nSECURITIES\\nAND EXCHANGE COMMI...   \n",
       "3  UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...   \n",
       "4                                                      \n",
       "\n",
       "                                        cleaned_text  negative  neutral  \\\n",
       "0  Table of Contents\\nUNITED STATES SECURITIES AN...       0.0      0.0   \n",
       "1  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...       1.0      0.0   \n",
       "2  UNITED\\nSTATES\\nSECURITIES\\nAND EXCHANGE COMMI...       0.0      0.0   \n",
       "3  UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...       0.0      0.0   \n",
       "4                                                          0.0      0.0   \n",
       "\n",
       "   positive  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f164c4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/100: 1 800 FLOWERS COM INC\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (597) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33mCompany Name\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m text_chunks = chunk_text(row[\u001b[33m'\u001b[39m\u001b[33mcleaned_text\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m chunk_sentiments = \u001b[43mget_sentiment_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_chunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m result = aggregate_sentiment(chunk_sentiments)\n\u001b[32m     18\u001b[39m sentiment_results.append(result)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mget_sentiment_scores\u001b[39m\u001b[34m(chunks)\u001b[39m\n\u001b[32m      4\u001b[39m inputs = tokenizer(chunk, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m, truncation=\u001b[38;5;28;01mTrue\u001b[39;00m, padding=\u001b[38;5;28;01mTrue\u001b[39;00m).to(device)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m probs = torch.nn.functional.softmax(outputs.logits, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m      8\u001b[39m label = torch.argmax(probs, dim=\u001b[32m1\u001b[39m).item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenv/project10k/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenv/project10k/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenv/project10k/lib/python3.13/site-packages/transformers/models/bert/modeling_bert.py:1673\u001b[39m, in \u001b[36mBertForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1665\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1666\u001b[39m \u001b[33;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[32m   1667\u001b[39m \u001b[33;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[32m   1668\u001b[39m \u001b[33;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[32m   1669\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m   1670\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1671\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1673\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1674\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1677\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1679\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1680\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1681\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1683\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1685\u001b[39m pooled_output = outputs[\u001b[32m1\u001b[39m]\n\u001b[32m   1687\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.dropout(pooled_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenv/project10k/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenv/project10k/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenv/project10k/lib/python3.13/site-packages/transformers/models/bert/modeling_bert.py:1078\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1075\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1076\u001b[39m         token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n\u001b[32m-> \u001b[39m\u001b[32m1078\u001b[39m embedding_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1082\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1083\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1084\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1086\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1087\u001b[39m     attention_mask = torch.ones((batch_size, seq_length + past_key_values_length), device=device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenv/project10k/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenv/project10k/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenv/project10k/lib/python3.13/site-packages/transformers/models/bert/modeling_bert.py:217\u001b[39m, in \u001b[36mBertEmbeddings.forward\u001b[39m\u001b[34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.position_embedding_type == \u001b[33m\"\u001b[39m\u001b[33mabsolute\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    216\u001b[39m     position_embeddings = \u001b[38;5;28mself\u001b[39m.position_embeddings(position_ids)\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     \u001b[43membeddings\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_embeddings\u001b[49m\n\u001b[32m    218\u001b[39m embeddings = \u001b[38;5;28mself\u001b[39m.LayerNorm(embeddings)\n\u001b[32m    219\u001b[39m embeddings = \u001b[38;5;28mself\u001b[39m.dropout(embeddings)\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (597) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# # # Load your dataframe\n",
    "# # df = pd.read_csv(\"your_cleaned_10k_dataframe.csv\")\n",
    "\n",
    "# # Optional: keep only non-null cleaned_text\n",
    "# df = df_100[df_100['cleaned_text'].notnull()].reset_index(drop=True)\n",
    "\n",
    "# # Storage\n",
    "# sentiment_results = []\n",
    "\n",
    "# # Iterate through each filing\n",
    "# for i, row in df.iterrows():\n",
    "#     print(f\"Processing {i+1}/{len(df)}: {row['Company Name']}\")\n",
    "#     text_chunks = chunk_text(row['cleaned_text'])\n",
    "#     chunk_sentiments = get_sentiment_scores(text_chunks)\n",
    "#     result = aggregate_sentiment(chunk_sentiments)\n",
    "#     sentiment_results.append(result)\n",
    "\n",
    "# # Convert results to DataFrame\n",
    "# sentiment_df = pd.DataFrame(sentiment_results)\n",
    "\n",
    "# # Combine with original data\n",
    "# final_df = pd.concat([df, sentiment_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88da0184-1200-4d28-a892-86919c1196ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"10K_filings_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc5052f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (4.50.3)\n",
      "Requirement already satisfied: filelock in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from requests->transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19ce1ad4-7ba0-486e-9e76-059efc52c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_item(text, item_number):\n",
    "    \"\"\"\n",
    "    Extracts section like ITEM 1A, ITEM 7 from 10-K text\n",
    "    \"\"\"\n",
    "    pattern = rf'(ITEM\\s+{item_number}[^\\n]*)(.*?)(ITEM\\s+\\d+[A-Z]?)'\n",
    "    match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(2).strip()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbe02928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=500, overlap=50):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = \" \".join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "839d3179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18283.26s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from torch) (4.13.0)\n",
      "Requirement already satisfied: networkx in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from torch) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from torchvision) (2.2.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377319e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffec2876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56dfb4de787b47d3aab4868ea0645292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10adb0bebb79429797e509ce1c8c1393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5601fdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "finbert = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6694a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    chunks = chunk_text(text)\n",
    "    labels = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        result = finbert(chunk[:512])[0]  # Truncate to 512 tokens\n",
    "        labels.append(result[\"label\"])\n",
    "\n",
    "    # Aggregate: count the most common sentiment\n",
    "    count = Counter(labels)\n",
    "    dominant_sentiment = count.most_common(1)[0][0]\n",
    "    \n",
    "    return dominant_sentiment, dict(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfbb015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1000 = df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce1e3744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/vt1xc8rs7w9f0fs5spyxbzcc0000gn/T/ipykernel_16162/2872544260.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_1000[\"sentiment_result\"] = df_1000[\"cleaned_text\"].apply(lambda x: analyze_sentiment(x)[0])\n",
      "/var/folders/w1/vt1xc8rs7w9f0fs5spyxbzcc0000gn/T/ipykernel_16162/2872544260.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_1000[\"sentiment_breakdown\"] = df_1000[\"cleaned_text\"].apply(lambda x: analyze_sentiment(x)[1])\n"
     ]
    }
   ],
   "source": [
    "# Assuming df_1000 contains a 'cleaned_text' column\n",
    "df_1000[\"sentiment_result\"] = df_1000[\"cleaned_text\"].apply(lambda x: analyze_sentiment(x)[0])\n",
    "df_1000[\"sentiment_breakdown\"] = df_1000[\"cleaned_text\"].apply(lambda x: analyze_sentiment(x)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1ac91c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_folder</th>\n",
       "      <th>quarter_folder</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>filing_type</th>\n",
       "      <th>cik</th>\n",
       "      <th>accession</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment_result</th>\n",
       "      <th>sentiment_breakdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220520</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>849399</td>\n",
       "      <td>20220520_10-K_edgar_data_849399_0000849399-22-...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220520_...</td>\n",
       "      <td>20220520_10-K_edgar_data_849399_0000849399-22-...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>{'neutral': 72, 'positive': 11, 'negative': 16}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220613</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>1857910</td>\n",
       "      <td>20220613_10-K_edgar_data_1857910_0001599916-22...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220613_...</td>\n",
       "      <td>20220613_10-K_edgar_data_1857910_0001599916-22...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>{'neutral': 27, 'positive': 2, 'negative': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220414</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>1855751</td>\n",
       "      <td>20220414_10-K_edgar_data_1855751_0001493152-22...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220414_...</td>\n",
       "      <td>20220414_10-K_edgar_data_1855751_0001493152-22...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>{'neutral': 101, 'positive': 4, 'negative': 9}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220404</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>748790</td>\n",
       "      <td>20220404_10-K_edgar_data_748790_0001575872-22-...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220404_...</td>\n",
       "      <td>20220404_10-K_edgar_data_748790_0001575872-22-...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>{'neutral': 144, 'positive': 13, 'negative': 14}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220408</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>1512927</td>\n",
       "      <td>20220408_10-K_edgar_data_1512927_0001410578-22...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220408_...</td>\n",
       "      <td>20220408_10-K_edgar_data_1512927_0001410578-22...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>{'neutral': 102, 'positive': 6, 'negative': 9}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_folder quarter_folder  filing_date  year  month  day filing_type  \\\n",
       "0         2022           QTR2     20220520  2022      5   20        10-K   \n",
       "1         2022           QTR2     20220613  2022      6   13        10-K   \n",
       "2         2022           QTR2     20220414  2022      4   14        10-K   \n",
       "3         2022           QTR2     20220404  2022      4    4        10-K   \n",
       "4         2022           QTR2     20220408  2022      4    8        10-K   \n",
       "\n",
       "    cik  accession                                           filename  \\\n",
       "0  data     849399  20220520_10-K_edgar_data_849399_0000849399-22-...   \n",
       "1  data    1857910  20220613_10-K_edgar_data_1857910_0001599916-22...   \n",
       "2  data    1855751  20220414_10-K_edgar_data_1855751_0001493152-22...   \n",
       "3  data     748790  20220404_10-K_edgar_data_748790_0001575872-22-...   \n",
       "4  data    1512927  20220408_10-K_edgar_data_1512927_0001410578-22...   \n",
       "\n",
       "                                                text  \\\n",
       "0  <Header>\\n<FileStats>\\n    <FileName>20220520_...   \n",
       "1  <Header>\\n<FileStats>\\n    <FileName>20220613_...   \n",
       "2  <Header>\\n<FileStats>\\n    <FileName>20220414_...   \n",
       "3  <Header>\\n<FileStats>\\n    <FileName>20220404_...   \n",
       "4  <Header>\\n<FileStats>\\n    <FileName>20220408_...   \n",
       "\n",
       "                                        cleaned_text sentiment_result  \\\n",
       "0  20220520_10-K_edgar_data_849399_0000849399-22-...          neutral   \n",
       "1  20220613_10-K_edgar_data_1857910_0001599916-22...          neutral   \n",
       "2  20220414_10-K_edgar_data_1855751_0001493152-22...          neutral   \n",
       "3  20220404_10-K_edgar_data_748790_0001575872-22-...          neutral   \n",
       "4  20220408_10-K_edgar_data_1512927_0001410578-22...          neutral   \n",
       "\n",
       "                                sentiment_breakdown  \n",
       "0   {'neutral': 72, 'positive': 11, 'negative': 16}  \n",
       "1     {'neutral': 27, 'positive': 2, 'negative': 3}  \n",
       "2    {'neutral': 101, 'positive': 4, 'negative': 9}  \n",
       "3  {'neutral': 144, 'positive': 13, 'negative': 14}  \n",
       "4    {'neutral': 102, 'positive': 6, 'negative': 9}  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e186341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1000.to_csv(\"10K_with_sentiment.csv\", index=False)\n",
    "#df_1000[[\"file_name\", \"sentiment_result\", \"sentiment_breakdown\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2158dcfa",
   "metadata": {},
   "source": [
    "## Using LM lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10656ddd-7e65-404c-a47a-2f7937fc4d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/nareshchethala/Desktop/University/Spring_25/BAIM_660/Project/10K_filings_all_years.csv\")  #5m 33sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80860415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_folder</th>\n",
       "      <th>quarter_folder</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>filing_type</th>\n",
       "      <th>cik</th>\n",
       "      <th>accession</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220520</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>849399</td>\n",
       "      <td>20220520_10-K_edgar_data_849399_0000849399-22-...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220520_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220613</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>1857910</td>\n",
       "      <td>20220613_10-K_edgar_data_1857910_0001599916-22...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220613_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220414</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>1855751</td>\n",
       "      <td>20220414_10-K_edgar_data_1855751_0001493152-22...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220414_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220404</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>748790</td>\n",
       "      <td>20220404_10-K_edgar_data_748790_0001575872-22-...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220404_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220408</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>1512927</td>\n",
       "      <td>20220408_10-K_edgar_data_1512927_0001410578-22...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220408_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_folder quarter_folder  filing_date  year  month  day filing_type  \\\n",
       "0         2022           QTR2     20220520  2022      5   20        10-K   \n",
       "1         2022           QTR2     20220613  2022      6   13        10-K   \n",
       "2         2022           QTR2     20220414  2022      4   14        10-K   \n",
       "3         2022           QTR2     20220404  2022      4    4        10-K   \n",
       "4         2022           QTR2     20220408  2022      4    8        10-K   \n",
       "\n",
       "    cik  accession                                           filename  \\\n",
       "0  data     849399  20220520_10-K_edgar_data_849399_0000849399-22-...   \n",
       "1  data    1857910  20220613_10-K_edgar_data_1857910_0001599916-22...   \n",
       "2  data    1855751  20220414_10-K_edgar_data_1855751_0001493152-22...   \n",
       "3  data     748790  20220404_10-K_edgar_data_748790_0001575872-22-...   \n",
       "4  data    1512927  20220408_10-K_edgar_data_1512927_0001410578-22...   \n",
       "\n",
       "                                                text  \n",
       "0  <Header>\\n<FileStats>\\n    <FileName>20220520_...  \n",
       "1  <Header>\\n<FileStats>\\n    <FileName>20220613_...  \n",
       "2  <Header>\\n<FileStats>\\n    <FileName>20220414_...  \n",
       "3  <Header>\\n<FileStats>\\n    <FileName>20220404_...  \n",
       "4  <Header>\\n<FileStats>\\n    <FileName>20220408_...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc0c0b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_cleaner(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    # Remove HTML/XML tags\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)\n",
    "\n",
    "    # Remove SEC headers\n",
    "    text = re.sub(r'(?s)<SEC-Header>.*?</SEC-Header>', ' ', text)\n",
    "    text = re.sub(r'(?s)<Header>.*?</Header>', ' ', text)\n",
    "\n",
    "    # Remove file meta like \"file name xyz.txt\"\n",
    "    text = re.sub(r'(?i)file name.*?\\.txt', ' ', text)\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', ' ', text)\n",
    "\n",
    "    # Remove excessive punctuation and underscores\n",
    "    text = re.sub(r'[_*=-]{2,}', ' ', text)\n",
    "\n",
    "    # Collapse multiple newlines and spaces\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59c500c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_100=df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56cdf337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/vt1xc8rs7w9f0fs5spyxbzcc0000gn/T/ipykernel_56483/4209915209.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_100[\"cleaned_text\"] = df_100[\"text\"].apply(basic_cleaner) #10min 32.4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Apply initial cleaning\n",
    "df_100[\"cleaned_text\"] = df_100[\"text\"].apply(basic_cleaner) #10min 32.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5df003f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/nareshchethala/.virtualenv/project10k/lib/python3.13/site-packages (from nltk) (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb1d23db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nareshchethala/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a923c92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/vt1xc8rs7w9f0fs5spyxbzcc0000gn/T/ipykernel_56483/1067324900.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_100[\"normalized_text\"] = df_100[\"cleaned_text\"].apply(clean_for_lm_modeling)\n"
     ]
    }
   ],
   "source": [
    "# Final preprocessing for LM-based sentiment\n",
    "def clean_for_lm_modeling(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    text = text.lower()\n",
    "    text = text.encode(\"ascii\", \"ignore\").decode()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\d+\", \" \", text)\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "# Apply to cleaned_text\n",
    "df_100[\"normalized_text\"] = df_100[\"cleaned_text\"].apply(clean_for_lm_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5411d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_folder</th>\n",
       "      <th>quarter_folder</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>filing_type</th>\n",
       "      <th>cik</th>\n",
       "      <th>accession</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220520</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>849399</td>\n",
       "      <td>20220520_10-K_edgar_data_849399_0000849399-22-...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220520_...</td>\n",
       "      <td>20220520_10-K_edgar_data_849399_0000849399-22-...</td>\n",
       "      <td>_ k_edgar_data_ _ txt hdr sgml accession numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220613</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>1857910</td>\n",
       "      <td>20220613_10-K_edgar_data_1857910_0001599916-22...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220613_...</td>\n",
       "      <td>20220613_10-K_edgar_data_1857910_0001599916-22...</td>\n",
       "      <td>_ k_edgar_data_ _ txt hdr sgml accession numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220414</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>1855751</td>\n",
       "      <td>20220414_10-K_edgar_data_1855751_0001493152-22...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220414_...</td>\n",
       "      <td>20220414_10-K_edgar_data_1855751_0001493152-22...</td>\n",
       "      <td>_ k_edgar_data_ _ txt hdr sgml accession numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220404</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>748790</td>\n",
       "      <td>20220404_10-K_edgar_data_748790_0001575872-22-...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220404_...</td>\n",
       "      <td>20220404_10-K_edgar_data_748790_0001575872-22-...</td>\n",
       "      <td>_ k_edgar_data_ _ txt hdr sgml accession numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220408</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>1512927</td>\n",
       "      <td>20220408_10-K_edgar_data_1512927_0001410578-22...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220408_...</td>\n",
       "      <td>20220408_10-K_edgar_data_1512927_0001410578-22...</td>\n",
       "      <td>_ k_edgar_data_ _ txt hdr sgml accession numbe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_folder quarter_folder  filing_date  year  month  day filing_type  \\\n",
       "0         2022           QTR2     20220520  2022      5   20        10-K   \n",
       "1         2022           QTR2     20220613  2022      6   13        10-K   \n",
       "2         2022           QTR2     20220414  2022      4   14        10-K   \n",
       "3         2022           QTR2     20220404  2022      4    4        10-K   \n",
       "4         2022           QTR2     20220408  2022      4    8        10-K   \n",
       "\n",
       "    cik  accession                                           filename  \\\n",
       "0  data     849399  20220520_10-K_edgar_data_849399_0000849399-22-...   \n",
       "1  data    1857910  20220613_10-K_edgar_data_1857910_0001599916-22...   \n",
       "2  data    1855751  20220414_10-K_edgar_data_1855751_0001493152-22...   \n",
       "3  data     748790  20220404_10-K_edgar_data_748790_0001575872-22-...   \n",
       "4  data    1512927  20220408_10-K_edgar_data_1512927_0001410578-22...   \n",
       "\n",
       "                                                text  \\\n",
       "0  <Header>\\n<FileStats>\\n    <FileName>20220520_...   \n",
       "1  <Header>\\n<FileStats>\\n    <FileName>20220613_...   \n",
       "2  <Header>\\n<FileStats>\\n    <FileName>20220414_...   \n",
       "3  <Header>\\n<FileStats>\\n    <FileName>20220404_...   \n",
       "4  <Header>\\n<FileStats>\\n    <FileName>20220408_...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  20220520_10-K_edgar_data_849399_0000849399-22-...   \n",
       "1  20220613_10-K_edgar_data_1857910_0001599916-22...   \n",
       "2  20220414_10-K_edgar_data_1855751_0001493152-22...   \n",
       "3  20220404_10-K_edgar_data_748790_0001575872-22-...   \n",
       "4  20220408_10-K_edgar_data_1512927_0001410578-22...   \n",
       "\n",
       "                                     normalized_text  \n",
       "0  _ k_edgar_data_ _ txt hdr sgml accession numbe...  \n",
       "1  _ k_edgar_data_ _ txt hdr sgml accession numbe...  \n",
       "2  _ k_edgar_data_ _ txt hdr sgml accession numbe...  \n",
       "3  _ k_edgar_data_ _ txt hdr sgml accession numbe...  \n",
       "4  _ k_edgar_data_ _ txt hdr sgml accession numbe...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb72f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_1000 = df.head(1000).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549ad98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_folder</th>\n",
       "      <th>quarter_folder</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>filing_type</th>\n",
       "      <th>cik</th>\n",
       "      <th>accession</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220520</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>849399</td>\n",
       "      <td>20220520_10-K_edgar_data_849399_0000849399-22-...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220520_...</td>\n",
       "      <td>20220520_10-K_edgar_data_849399_0000849399-22-...</td>\n",
       "      <td>_ k_edgar_data_ _ txt hdr sgml accession numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220613</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>1857910</td>\n",
       "      <td>20220613_10-K_edgar_data_1857910_0001599916-22...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220613_...</td>\n",
       "      <td>20220613_10-K_edgar_data_1857910_0001599916-22...</td>\n",
       "      <td>_ k_edgar_data_ _ txt hdr sgml accession numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220414</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>1855751</td>\n",
       "      <td>20220414_10-K_edgar_data_1855751_0001493152-22...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220414_...</td>\n",
       "      <td>20220414_10-K_edgar_data_1855751_0001493152-22...</td>\n",
       "      <td>_ k_edgar_data_ _ txt hdr sgml accession numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220404</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>748790</td>\n",
       "      <td>20220404_10-K_edgar_data_748790_0001575872-22-...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220404_...</td>\n",
       "      <td>20220404_10-K_edgar_data_748790_0001575872-22-...</td>\n",
       "      <td>_ k_edgar_data_ _ txt hdr sgml accession numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220408</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>1512927</td>\n",
       "      <td>20220408_10-K_edgar_data_1512927_0001410578-22...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220408_...</td>\n",
       "      <td>20220408_10-K_edgar_data_1512927_0001410578-22...</td>\n",
       "      <td>_ k_edgar_data_ _ txt hdr sgml accession numbe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_folder quarter_folder  filing_date  year  month  day filing_type  \\\n",
       "0         2022           QTR2     20220520  2022      5   20        10-K   \n",
       "1         2022           QTR2     20220613  2022      6   13        10-K   \n",
       "2         2022           QTR2     20220414  2022      4   14        10-K   \n",
       "3         2022           QTR2     20220404  2022      4    4        10-K   \n",
       "4         2022           QTR2     20220408  2022      4    8        10-K   \n",
       "\n",
       "    cik  accession                                           filename  \\\n",
       "0  data     849399  20220520_10-K_edgar_data_849399_0000849399-22-...   \n",
       "1  data    1857910  20220613_10-K_edgar_data_1857910_0001599916-22...   \n",
       "2  data    1855751  20220414_10-K_edgar_data_1855751_0001493152-22...   \n",
       "3  data     748790  20220404_10-K_edgar_data_748790_0001575872-22-...   \n",
       "4  data    1512927  20220408_10-K_edgar_data_1512927_0001410578-22...   \n",
       "\n",
       "                                                text  \\\n",
       "0  <Header>\\n<FileStats>\\n    <FileName>20220520_...   \n",
       "1  <Header>\\n<FileStats>\\n    <FileName>20220613_...   \n",
       "2  <Header>\\n<FileStats>\\n    <FileName>20220414_...   \n",
       "3  <Header>\\n<FileStats>\\n    <FileName>20220404_...   \n",
       "4  <Header>\\n<FileStats>\\n    <FileName>20220408_...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  20220520_10-K_edgar_data_849399_0000849399-22-...   \n",
       "1  20220613_10-K_edgar_data_1857910_0001599916-22...   \n",
       "2  20220414_10-K_edgar_data_1855751_0001493152-22...   \n",
       "3  20220404_10-K_edgar_data_748790_0001575872-22-...   \n",
       "4  20220408_10-K_edgar_data_1512927_0001410578-22...   \n",
       "\n",
       "                                     normalized_text  \n",
       "0  _ k_edgar_data_ _ txt hdr sgml accession numbe...  \n",
       "1  _ k_edgar_data_ _ txt hdr sgml accession numbe...  \n",
       "2  _ k_edgar_data_ _ txt hdr sgml accession numbe...  \n",
       "3  _ k_edgar_data_ _ txt hdr sgml accession numbe...  \n",
       "4  _ k_edgar_data_ _ txt hdr sgml accession numbe...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_1000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85776789",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_df = pd.read_csv(\"/Users/nareshchethala/Desktop/University/Spring_25/BAIM_660/Project/Loughran-McDonald_MasterDictionary_1993-2024.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d999d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dictionary and lowercase words\n",
    "lm_df[\"Word\"] = lm_df[\"Word\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25044f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Seq_num</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Word Proportion</th>\n",
       "      <th>Average Proportion</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Doc Count</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>Strong_Modal</th>\n",
       "      <th>Weak_Modal</th>\n",
       "      <th>Constraining</th>\n",
       "      <th>Complexity</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>1</td>\n",
       "      <td>755</td>\n",
       "      <td>2.955070e-08</td>\n",
       "      <td>1.945421e-08</td>\n",
       "      <td>4.078069e-06</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aardvarks</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.174200e-10</td>\n",
       "      <td>8.060019e-12</td>\n",
       "      <td>8.919011e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abaci</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3.522600e-10</td>\n",
       "      <td>1.089343e-10</td>\n",
       "      <td>5.105359e-08</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aback</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1.135060e-09</td>\n",
       "      <td>6.197922e-10</td>\n",
       "      <td>1.539279e-07</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abacus</td>\n",
       "      <td>5</td>\n",
       "      <td>9620</td>\n",
       "      <td>3.765268e-07</td>\n",
       "      <td>3.825261e-07</td>\n",
       "      <td>3.421836e-05</td>\n",
       "      <td>1295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abacuses</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abaft</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1.565600e-10</td>\n",
       "      <td>2.144787e-11</td>\n",
       "      <td>2.373367e-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abalone</td>\n",
       "      <td>8</td>\n",
       "      <td>149</td>\n",
       "      <td>5.831860e-09</td>\n",
       "      <td>4.729504e-09</td>\n",
       "      <td>1.031859e-06</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>abalones</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3.914000e-11</td>\n",
       "      <td>7.715206e-11</td>\n",
       "      <td>8.537449e-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abandon</td>\n",
       "      <td>10</td>\n",
       "      <td>154158</td>\n",
       "      <td>6.033745e-06</td>\n",
       "      <td>4.824004e-06</td>\n",
       "      <td>3.261271e-05</td>\n",
       "      <td>76324</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word  Seq_num  Word Count  Word Proportion  Average Proportion  \\\n",
       "0   aardvark        1         755     2.955070e-08        1.945421e-08   \n",
       "1  aardvarks        2           3     1.174200e-10        8.060019e-12   \n",
       "2      abaci        3           9     3.522600e-10        1.089343e-10   \n",
       "3      aback        4          29     1.135060e-09        6.197922e-10   \n",
       "4     abacus        5        9620     3.765268e-07        3.825261e-07   \n",
       "5   abacuses        6           0     0.000000e+00        0.000000e+00   \n",
       "6      abaft        7           4     1.565600e-10        2.144787e-11   \n",
       "7    abalone        8         149     5.831860e-09        4.729504e-09   \n",
       "8   abalones        9           1     3.914000e-11        7.715206e-11   \n",
       "9    abandon       10      154158     6.033745e-06        4.824004e-06   \n",
       "\n",
       "        Std Dev  Doc Count  Negative  Positive  Uncertainty  Litigious  \\\n",
       "0  4.078069e-06        140         0         0            0          0   \n",
       "1  8.919011e-09          1         0         0            0          0   \n",
       "2  5.105359e-08          7         0         0            0          0   \n",
       "3  1.539279e-07         28         0         0            0          0   \n",
       "4  3.421836e-05       1295         0         0            0          0   \n",
       "5  0.000000e+00          0         0         0            0          0   \n",
       "6  2.373367e-08          1         0         0            0          0   \n",
       "7  1.031859e-06         52         0         0            0          0   \n",
       "8  8.537449e-08          1         0         0            0          0   \n",
       "9  3.261271e-05      76324      2009         0            0          0   \n",
       "\n",
       "   Strong_Modal  Weak_Modal  Constraining  Complexity  Syllables     Source  \n",
       "0             0           0             0           0          2  12of12inf  \n",
       "1             0           0             0           0          2  12of12inf  \n",
       "2             0           0             0           0          3  12of12inf  \n",
       "3             0           0             0           0          2  12of12inf  \n",
       "4             0           0             0           0          3  12of12inf  \n",
       "5             0           0             0           0          4  12of12inf  \n",
       "6             0           0             0           0          2  12of12inf  \n",
       "7             0           0             0           0          4  12of12inf  \n",
       "8             0           0             0           0          4  12of12inf  \n",
       "9             0           0             0           0          3  12of12inf  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(lm_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aa2109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping column names to simplified category names\n",
    "category_columns = {\n",
    "    \"positive\": \"Positive\",\n",
    "    \"negative\": \"Negative\",\n",
    "    \"uncertainty\": \"Uncertainty\",\n",
    "    \"litigious\": \"Litigious\",\n",
    "    \"strong_modal\": \"Strong_Modal\",\n",
    "    \"weak_modal\": \"Weak_Modal\",\n",
    "    \"constraining\": \"Constraining\"\n",
    "}\n",
    "\n",
    "# Create a dictionary of category sets\n",
    "lm_lexicons = {\n",
    "    category: set(lm_df[lm_df[col] > 0][\"Word\"].str.lower())\n",
    "    for category, col in category_columns.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd3886c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping column names to simplified category names\n",
    "category_columns = {\n",
    "    \"positive\": \"Positive\",\n",
    "    \"negative\": \"Negative\",\n",
    "}\n",
    "\n",
    "# Create a dictionary of category sets\n",
    "lm_lexicons = {\n",
    "    category: set(lm_df[lm_df[col] > 0][\"Word\"].str.lower())\n",
    "    for category, col in category_columns.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1272a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def lm_sentiment_all_classes(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    counts = defaultdict(int)\n",
    "\n",
    "    for word in words:\n",
    "        for category, word_set in lm_lexicons.items():\n",
    "            if word in word_set:\n",
    "                counts[category] += 1\n",
    "\n",
    "    return dict(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3575b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/vt1xc8rs7w9f0fs5spyxbzcc0000gn/T/ipykernel_56483/3426006730.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_100[\"lm_sentiment_breakdown\"] = df_100[\"normalized_text\"].apply(lm_sentiment_all_classes)\n"
     ]
    }
   ],
   "source": [
    "df_100[\"lm_sentiment_breakdown\"] = df_100[\"normalized_text\"].apply(lm_sentiment_all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4542f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_folder</th>\n",
       "      <th>quarter_folder</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>filing_type</th>\n",
       "      <th>cik</th>\n",
       "      <th>accession</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lm_sentiment_breakdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220520</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>849399</td>\n",
       "      <td>20220520_10-K_edgar_data_849399_0000849399-22-...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220520_...</td>\n",
       "      <td>20220520_10-K_edgar_data_849399_0000849399-22-...</td>\n",
       "      <td>_ k_edgar_data_ _ txt hdr sgml accession numbe...</td>\n",
       "      <td>{'positive': 279, 'negative': 1082}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220613</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>1857910</td>\n",
       "      <td>20220613_10-K_edgar_data_1857910_0001599916-22...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220613_...</td>\n",
       "      <td>20220613_10-K_edgar_data_1857910_0001599916-22...</td>\n",
       "      <td>_ k_edgar_data_ _ txt hdr sgml accession numbe...</td>\n",
       "      <td>{'negative': 163, 'positive': 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220414</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>1855751</td>\n",
       "      <td>20220414_10-K_edgar_data_1855751_0001493152-22...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220414_...</td>\n",
       "      <td>20220414_10-K_edgar_data_1855751_0001493152-22...</td>\n",
       "      <td>_ k_edgar_data_ _ txt hdr sgml accession numbe...</td>\n",
       "      <td>{'negative': 741, 'positive': 275}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220404</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>748790</td>\n",
       "      <td>20220404_10-K_edgar_data_748790_0001575872-22-...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220404_...</td>\n",
       "      <td>20220404_10-K_edgar_data_748790_0001575872-22-...</td>\n",
       "      <td>_ k_edgar_data_ _ txt hdr sgml accession numbe...</td>\n",
       "      <td>{'negative': 1192, 'positive': 349}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>QTR2</td>\n",
       "      <td>20220408</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10-K</td>\n",
       "      <td>data</td>\n",
       "      <td>1512927</td>\n",
       "      <td>20220408_10-K_edgar_data_1512927_0001410578-22...</td>\n",
       "      <td>&lt;Header&gt;\\n&lt;FileStats&gt;\\n    &lt;FileName&gt;20220408_...</td>\n",
       "      <td>20220408_10-K_edgar_data_1512927_0001410578-22...</td>\n",
       "      <td>_ k_edgar_data_ _ txt hdr sgml accession numbe...</td>\n",
       "      <td>{'negative': 507, 'positive': 289}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_folder quarter_folder  filing_date  year  month  day filing_type  \\\n",
       "0         2022           QTR2     20220520  2022      5   20        10-K   \n",
       "1         2022           QTR2     20220613  2022      6   13        10-K   \n",
       "2         2022           QTR2     20220414  2022      4   14        10-K   \n",
       "3         2022           QTR2     20220404  2022      4    4        10-K   \n",
       "4         2022           QTR2     20220408  2022      4    8        10-K   \n",
       "\n",
       "    cik  accession                                           filename  \\\n",
       "0  data     849399  20220520_10-K_edgar_data_849399_0000849399-22-...   \n",
       "1  data    1857910  20220613_10-K_edgar_data_1857910_0001599916-22...   \n",
       "2  data    1855751  20220414_10-K_edgar_data_1855751_0001493152-22...   \n",
       "3  data     748790  20220404_10-K_edgar_data_748790_0001575872-22-...   \n",
       "4  data    1512927  20220408_10-K_edgar_data_1512927_0001410578-22...   \n",
       "\n",
       "                                                text  \\\n",
       "0  <Header>\\n<FileStats>\\n    <FileName>20220520_...   \n",
       "1  <Header>\\n<FileStats>\\n    <FileName>20220613_...   \n",
       "2  <Header>\\n<FileStats>\\n    <FileName>20220414_...   \n",
       "3  <Header>\\n<FileStats>\\n    <FileName>20220404_...   \n",
       "4  <Header>\\n<FileStats>\\n    <FileName>20220408_...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  20220520_10-K_edgar_data_849399_0000849399-22-...   \n",
       "1  20220613_10-K_edgar_data_1857910_0001599916-22...   \n",
       "2  20220414_10-K_edgar_data_1855751_0001493152-22...   \n",
       "3  20220404_10-K_edgar_data_748790_0001575872-22-...   \n",
       "4  20220408_10-K_edgar_data_1512927_0001410578-22...   \n",
       "\n",
       "                                     normalized_text  \\\n",
       "0  _ k_edgar_data_ _ txt hdr sgml accession numbe...   \n",
       "1  _ k_edgar_data_ _ txt hdr sgml accession numbe...   \n",
       "2  _ k_edgar_data_ _ txt hdr sgml accession numbe...   \n",
       "3  _ k_edgar_data_ _ txt hdr sgml accession numbe...   \n",
       "4  _ k_edgar_data_ _ txt hdr sgml accession numbe...   \n",
       "\n",
       "                lm_sentiment_breakdown  \n",
       "0  {'positive': 279, 'negative': 1082}  \n",
       "1    {'negative': 163, 'positive': 59}  \n",
       "2   {'negative': 741, 'positive': 275}  \n",
       "3  {'negative': 1192, 'positive': 349}  \n",
       "4   {'negative': 507, 'positive': 289}  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ecfb911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>lm_sentiment_breakdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20220520_10-K_edgar_data_849399_0000849399-22-...</td>\n",
       "      <td>{'positive': 279, 'negative': 1082}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20220613_10-K_edgar_data_1857910_0001599916-22...</td>\n",
       "      <td>{'negative': 163, 'positive': 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20220414_10-K_edgar_data_1855751_0001493152-22...</td>\n",
       "      <td>{'negative': 741, 'positive': 275}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20220404_10-K_edgar_data_748790_0001575872-22-...</td>\n",
       "      <td>{'negative': 1192, 'positive': 349}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20220408_10-K_edgar_data_1512927_0001410578-22...</td>\n",
       "      <td>{'negative': 507, 'positive': 289}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20220401_10-K_edgar_data_1511820_0001493152-22...</td>\n",
       "      <td>{'negative': 203, 'positive': 39}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20220429_10-K_edgar_data_1676047_0001213900-22...</td>\n",
       "      <td>{'negative': 897, 'positive': 285}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20220414_10-K_edgar_data_1637866_0001493152-22...</td>\n",
       "      <td>{'negative': 633, 'positive': 263}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20220413_10-K_edgar_data_1868269_0001104659-22...</td>\n",
       "      <td>{'negative': 1061, 'positive': 465}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20220412_10-K_edgar_data_1652958_0001683168-22...</td>\n",
       "      <td>{'negative': 822, 'positive': 147}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  20220520_10-K_edgar_data_849399_0000849399-22-...   \n",
       "1  20220613_10-K_edgar_data_1857910_0001599916-22...   \n",
       "2  20220414_10-K_edgar_data_1855751_0001493152-22...   \n",
       "3  20220404_10-K_edgar_data_748790_0001575872-22-...   \n",
       "4  20220408_10-K_edgar_data_1512927_0001410578-22...   \n",
       "5  20220401_10-K_edgar_data_1511820_0001493152-22...   \n",
       "6  20220429_10-K_edgar_data_1676047_0001213900-22...   \n",
       "7  20220414_10-K_edgar_data_1637866_0001493152-22...   \n",
       "8  20220413_10-K_edgar_data_1868269_0001104659-22...   \n",
       "9  20220412_10-K_edgar_data_1652958_0001683168-22...   \n",
       "\n",
       "                lm_sentiment_breakdown  \n",
       "0  {'positive': 279, 'negative': 1082}  \n",
       "1    {'negative': 163, 'positive': 59}  \n",
       "2   {'negative': 741, 'positive': 275}  \n",
       "3  {'negative': 1192, 'positive': 349}  \n",
       "4   {'negative': 507, 'positive': 289}  \n",
       "5    {'negative': 203, 'positive': 39}  \n",
       "6   {'negative': 897, 'positive': 285}  \n",
       "7   {'negative': 633, 'positive': 263}  \n",
       "8  {'negative': 1061, 'positive': 465}  \n",
       "9   {'negative': 822, 'positive': 147}  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100[[\"filename\", \"lm_sentiment_breakdown\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f2edd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1000.to_csv(\"10K_with_lm_sentiment_1000.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5e8933a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/vt1xc8rs7w9f0fs5spyxbzcc0000gn/T/ipykernel_56483/1919811944.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_100[\"lm_dominant_sentiment\"] = df_100[\"lm_sentiment_breakdown\"].apply(dominant_lm_category)\n"
     ]
    }
   ],
   "source": [
    "def dominant_lm_category(counts_dict):\n",
    "    if not counts_dict:\n",
    "        return \"NEUTRAL\"\n",
    "    return max(counts_dict.items(), key=lambda x: x[1])[0].upper()\n",
    "\n",
    "df_100[\"lm_dominant_sentiment\"] = df_100[\"lm_sentiment_breakdown\"].apply(dominant_lm_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da00f573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>lm_dominant_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20220520_10-K_edgar_data_849399_0000849399-22-...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20220613_10-K_edgar_data_1857910_0001599916-22...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20220414_10-K_edgar_data_1855751_0001493152-22...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20220404_10-K_edgar_data_748790_0001575872-22-...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20220408_10-K_edgar_data_1512927_0001410578-22...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20220401_10-K_edgar_data_1511820_0001493152-22...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20220429_10-K_edgar_data_1676047_0001213900-22...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20220414_10-K_edgar_data_1637866_0001493152-22...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20220413_10-K_edgar_data_1868269_0001104659-22...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20220412_10-K_edgar_data_1652958_0001683168-22...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename lm_dominant_sentiment\n",
       "0  20220520_10-K_edgar_data_849399_0000849399-22-...              NEGATIVE\n",
       "1  20220613_10-K_edgar_data_1857910_0001599916-22...              NEGATIVE\n",
       "2  20220414_10-K_edgar_data_1855751_0001493152-22...              NEGATIVE\n",
       "3  20220404_10-K_edgar_data_748790_0001575872-22-...              NEGATIVE\n",
       "4  20220408_10-K_edgar_data_1512927_0001410578-22...              NEGATIVE\n",
       "5  20220401_10-K_edgar_data_1511820_0001493152-22...              NEGATIVE\n",
       "6  20220429_10-K_edgar_data_1676047_0001213900-22...              NEGATIVE\n",
       "7  20220414_10-K_edgar_data_1637866_0001493152-22...              NEGATIVE\n",
       "8  20220413_10-K_edgar_data_1868269_0001104659-22...              NEGATIVE\n",
       "9  20220412_10-K_edgar_data_1652958_0001683168-22...              NEGATIVE"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100[[\"filename\", \"lm_dominant_sentiment\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df8663f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   year_folder             100 non-null    int64 \n",
      " 1   quarter_folder          100 non-null    object\n",
      " 2   filing_date             100 non-null    int64 \n",
      " 3   year                    100 non-null    int64 \n",
      " 4   month                   100 non-null    int64 \n",
      " 5   day                     100 non-null    int64 \n",
      " 6   filing_type             100 non-null    object\n",
      " 7   cik                     100 non-null    object\n",
      " 8   accession               100 non-null    int64 \n",
      " 9   filename                100 non-null    object\n",
      " 10  text                    100 non-null    object\n",
      " 11  cleaned_text            100 non-null    object\n",
      " 12  normalized_text         100 non-null    object\n",
      " 13  lm_sentiment_breakdown  100 non-null    object\n",
      " 14  lm_dominant_sentiment   100 non-null    object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 11.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_100.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "feb3f0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count          100\n",
       "unique           1\n",
       "top       NEGATIVE\n",
       "freq           100\n",
       "Name: lm_dominant_sentiment, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100[\"lm_dominant_sentiment\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0d8771",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project10K",
   "language": "python",
   "name": "project10k"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
